{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "447QQCqccyO-"
      },
      "source": [
        "# Model 2 training \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGed5XlRc3o2"
      },
      "source": [
        "## Before your running\n",
        "\n",
        "- Open GPU on Colab. Click `Runtime` -> `change runtime type`-> `select GPU`\n",
        "- Model 2's mask rcnn is runned on detectron2 platform for training. For more details,  please read detectron2 [repo](https://github.com/facebookresearch/detectron2), [tutorial notebook](https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5),[documentation](https://detectron2.readthedocs.io/en/latest/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8X0r-Fse6X_"
      },
      "source": [
        "## Trained weight of the model\n",
        "- The trained model weight is saved at `./output/`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM54r6jlKTII"
      },
      "source": [
        "# Install detectron2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_FzH13EjseR",
        "outputId": "44f2ffa5-c78e-4fd2-8125-9d07af9f0d53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyyaml==5.1 in /usr/local/lib/python3.7/dist-packages (5.1)\n",
            "1.8.1+cu101 True\n",
            "gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Copyright (C) 2017 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (3.6.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "# install dependencies: \n",
        "!pip install pyyaml==5.1\n",
        "!gcc --version\n",
        "!pip install gdown\n",
        "# opencv is pre-installed on colab\n",
        "\n",
        "# install detectron2: (Colab has CUDA 10.2 + torch 1.8)\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
        "!pip install torch==1.8.0 torchvision==0.9.0 torchaudio==0.8.0\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.8/index.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-i4hmGYk1dL",
        "outputId": "a980aaf8-4342-4af9-bedd-f0a010629338"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.8/index.html\n",
            "Requirement already satisfied: detectron2 in /usr/local/lib/python3.7/dist-packages (0.4+cu101)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from detectron2) (3.2.2)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.1.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.8.9)\n",
            "Requirement already satisfied: fvcore<0.1.4,>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.1.3.post20210317)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.16.0)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.1.8)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.5.0)\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (7.1.2)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.0.2)\n",
            "Requirement already satisfied: omegaconf>=2 in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.1.0)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from detectron2) (4.41.1)\n",
            "Requirement already satisfied: iopath>=0.1.2 in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.1.8)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (1.19.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (1.3.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.4,>=0.1.3->detectron2) (5.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (57.0.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.8.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.36.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.4.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (2.23.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.34.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (3.3.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.30.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.12.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.6.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (3.12.4)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools>=2.0.2->detectron2) (0.29.23)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.7/dist-packages (from omegaconf>=2->detectron2) (4.8)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from iopath>=0.1.2->detectron2) (2.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->detectron2) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (1.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->detectron2) (4.0.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (0.2.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->detectron2) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->detectron2) (3.7.4.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard->detectron2) (0.4.8)\n"
          ]
        }
      ],
      "source": [
        "import torch, torchvision\n",
        "assert torch.__version__.startswith(\"1.8\")   # need to manually install torch 1.8 if Colab changes its default version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyAvNCJMmvFF"
      },
      "outputs": [],
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2bjrfb2LDeo"
      },
      "source": [
        "# Train on a building dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjbUIhSxUdm_"
      },
      "source": [
        "In this section, we show how to train an existing detectron2 model on a custom dataset in a new format.\n",
        "\n",
        "We use our building image dataset\n",
        "which only has 3 class: masonry, m6 and rcw\n",
        "\n",
        "We'll predict buidling type based on an existing model pre-trained on COCO dataset, available in detectron2's model zoo.\n",
        "\n",
        "Note that COCO dataset does not have 3 classed. We'll be able to recognize this new class in a few minutes.\n",
        "\n",
        "## Prepare the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRWlJNnP0DEV"
      },
      "source": [
        "In our mdel, **we use category opening, masonry, m6, rcw**, "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwwTzNAICkPT"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('/content/val_predict'):\n",
        "  os.makedirs('/content/val_predict')\n",
        "\n",
        "if not os.path.exists('/content/df'):\n",
        "  os.makedirs('/content/df')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVLr6PTsNHmx",
        "outputId": "96405241-cc58-4371-f303-de95094cc8a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path '/content/dataset' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "# Download buildings imgs data(traning set and val set) from github\n",
        "! git clone https://github.com/luoyaxiong/final.git  /content/project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cbgvk4xaB10j"
      },
      "outputs": [],
      "source": [
        "# address of building dataset\n",
        "DATASET_ADDRESS = '/content/project/code/data/traing_data/model2'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVJoOm6LVJwW"
      },
      "source": [
        "Register the building dataset to detectron2, following the [detectron2 custom dataset tutorial](https://detectron2.readthedocs.io/tutorials/datasets.html).\n",
        "Here, the dataset is in its custom format, therefore we write a function to parse it and prepare it into detectron2's standard format. User should write such a function when using a dataset in custom format. See the tutorial for more details.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIbAM2pv-urF"
      },
      "outputs": [],
      "source": [
        "# if your dataset is in COCO format, this cell can be replaced by the following three lines:\n",
        "# from detectron2.data.datasets import register_coco_instances\n",
        "# register_coco_instances(\"my_dataset_train\", {}, \"json_annotation_train.json\", \"path/to/image/dir\")\n",
        "# register_coco_instances(\"my_dataset_val\", {}, \"json_annotation_val.json\", \"path/to/image/dir\")\n",
        "\n",
        "from detectron2.structures import BoxMode\n",
        "\n",
        "def get_building_dicts(img_dir):\n",
        "    json_file = os.path.join(img_dir, \"via_region_data.json\")\n",
        "    with open(json_file) as f:\n",
        "        imgs_anns = json.load(f)\n",
        "\n",
        "    dataset_dicts = []\n",
        "    dict_category_id = {\n",
        "      'masonry':0,\n",
        "      'm6':1,\n",
        "      'rcw':2\n",
        "    }\n",
        "    for idx, v in enumerate(imgs_anns.values()):\n",
        "        record = {}\n",
        "        \n",
        "        filename = os.path.join(img_dir, v[\"filename\"])\n",
        "        height, width = cv2.imread(filename).shape[:2]\n",
        "        \n",
        "        record[\"file_name\"] = filename\n",
        "        record[\"image_id\"] = idx\n",
        "        record[\"height\"] = height\n",
        "        record[\"width\"] = width\n",
        "      \n",
        "        annos = v[\"regions\"]\n",
        "        objs = []\n",
        "        # since we use VIA 2.0 tool， annos is a list not a set\n",
        "        for idx, anno in enumerate(annos):\n",
        "\n",
        "            # assert not anno[\"region_attributes\"]\n",
        "            #  record category_id\n",
        "            category_id = dict_category_id[anno[\"region_attributes\"]['class_name']]\n",
        "            anno = anno[\"shape_attributes\"]\n",
        "            px = anno[\"all_points_x\"]\n",
        "            py = anno[\"all_points_y\"]\n",
        "            poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]\n",
        "            poly = [p for x in poly for p in x]\n",
        "\n",
        "            obj = {\n",
        "                \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n",
        "                \"bbox_mode\": BoxMode.XYXY_ABS,\n",
        "                \"segmentation\": [poly],\n",
        "                \"category_id\": category_id,\n",
        "            }\n",
        "            objs.append(obj)\n",
        "        record[\"annotations\"] = objs\n",
        "        dataset_dicts.append(record)\n",
        "    return dataset_dicts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZroYbYzE9Wr"
      },
      "outputs": [],
      "source": [
        "# add the dict to Cataclog\n",
        "for d in [\"train\", \"val\"]:\n",
        "    DatasetCatalog.register('building_'+d, lambda d=d: get_building_dicts(DATASET_ADDRESS+'/' + d))\n",
        "    MetadataCatalog.get('building_'+d).set(thing_classes=[\"masonry\",\"m6\",\"rcw\"])\n",
        "building_metadata = MetadataCatalog.get(\"building_train\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ljbWTX0Wi8E"
      },
      "source": [
        "To verify the data loading is correct, let's visualize the annotations of randomly selected samples in the training set:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlqXIXXhW8dA"
      },
      "source": [
        "## Train\n",
        "\n",
        "Now, fine-tune a cityscape-pretrained R50-FPN Mask R-CNN model on the building dataset. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dh8ZyOkbRp8P"
      },
      "source": [
        "There is no epoch parameter in this frame, but it provides IMS_PER_BATCH and MAX_ITER. We can calculate epoch from equation below:\n",
        "\n",
        "$$ Epoch = MAX\\_ITER * IMS\\_PER\\_BATCH  / TOTAL\\_NUM\\_IMAGES \n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2OyXqbIw_tC"
      },
      "outputs": [],
      "source": [
        "EPOCH = 20\n",
        "TOTAL_NUM_IMAGES = 449"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpJIeDdczBf6"
      },
      "outputs": [],
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"building_train\",)\n",
        "cfg.DATASETS.TEST = ()\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
        "cfg.SOLVER.MAX_ITER = int(EPOCH*TOTAL_NUM_IMAGES/cfg.SOLVER.IMS_PER_BATCH-1)     # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
        "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256   # faster, and good enough for this toy dataset (default: 512)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3  # 3 class (\"masonry\",\"m6\",\"rcw\"). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
        "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
        "\n",
        "# os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "# trainer = DefaultTrainer(cfg) \n",
        "# trainer.resume_or_load(resume=False)\n",
        "# trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSSfbyA8xiyw"
      },
      "outputs": [],
      "source": [
        "# Add validation loss \n",
        "from detectron2.engine import HookBase\n",
        "from detectron2.data import build_detection_train_loader\n",
        "import detectron2.utils.comm as comm\n",
        "\n",
        "cfg.DATASETS.VAL = (\"building_val\",)\n",
        "\n",
        "class ValidationLoss(HookBase):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg.clone()\n",
        "        self.cfg.DATASETS.TRAIN = cfg.DATASETS.VAL\n",
        "        self._loader = iter(build_detection_train_loader(self.cfg))\n",
        "        \n",
        "    def after_step(self):\n",
        "        data = next(self._loader)\n",
        "        with torch.no_grad():\n",
        "            loss_dict = self.trainer.model(data)\n",
        "            \n",
        "            losses = sum(loss_dict.values())\n",
        "            assert torch.isfinite(losses).all(), loss_dict\n",
        "\n",
        "            loss_dict_reduced = {\"val_\" + k: v.item() for k, v in \n",
        "                                 comm.reduce_dict(loss_dict).items()}\n",
        "            losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n",
        "            if comm.is_main_process():\n",
        "                self.trainer.storage.put_scalars(total_val_loss=losses_reduced, \n",
        "                                                 **loss_dict_reduced)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWWjE2II2P0S"
      },
      "outputs": [],
      "source": [
        "# ! rm -r /content/output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QWW1mCkxnXl",
        "outputId": "50324924-8087-48d4-e8b2-f588bb8906c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m[06/14 03:15:14 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (deconv_relu): ReLU()\n",
            "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[06/14 03:15:28 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 449 images left.\n",
            "\u001b[32m[06/14 03:15:28 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
            "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
            "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
            "|  masonry   | 243          |     m6     | 188          |    rcw     | 189          |\n",
            "|            |              |            |              |            |              |\n",
            "|   total    | 620          |            |              |            |              |\u001b[0m\n",
            "\u001b[32m[06/14 03:15:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[06/14 03:15:28 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "\u001b[32m[06/14 03:15:28 d2.data.common]: \u001b[0mSerializing 449 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[06/14 03:15:28 d2.data.common]: \u001b[0mSerialized dataset takes 0.38 MiB\n",
            "\u001b[32m[06/14 03:15:32 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 96 images left.\n",
            "\u001b[32m[06/14 03:15:32 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
            "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
            "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
            "|  masonry   | 44           |     m6     | 47           |    rcw     | 32           |\n",
            "|            |              |            |              |            |              |\n",
            "|   total    | 123          |            |              |            |              |\u001b[0m\n",
            "\u001b[32m[06/14 03:15:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[06/14 03:15:32 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "\u001b[32m[06/14 03:15:32 d2.data.common]: \u001b[0mSerializing 96 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[06/14 03:15:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m[06/14 03:15:32 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[06/14 03:15:38 d2.utils.events]: \u001b[0m eta: 0:12:53  iter: 19  total_loss: 2.187  loss_cls: 1.36  loss_box_reg: 0.01361  loss_mask: 0.6903  loss_rpn_cls: 0.1006  loss_rpn_loc: 0.0112  total_val_loss: 2.192  val_loss_cls: 1.344  val_loss_box_reg: 0.02658  val_loss_mask: 0.6926  val_loss_rpn_cls: 0.08547  val_loss_rpn_loc: 0.01016  time: 0.1739  data_time: 0.0398  lr: 4.9953e-06  max_mem: 2179M\n",
            "\u001b[32m[06/14 03:15:44 d2.utils.events]: \u001b[0m eta: 0:12:15  iter: 39  total_loss: 2.112  loss_cls: 1.223  loss_box_reg: 0.04137  loss_mask: 0.686  loss_rpn_cls: 0.1074  loss_rpn_loc: 0.01084  total_val_loss: 2.061  val_loss_cls: 1.217  val_loss_box_reg: 0.03967  val_loss_mask: 0.6907  val_loss_rpn_cls: 0.09979  val_loss_rpn_loc: 0.01208  time: 0.1714  data_time: 0.0238  lr: 9.9903e-06  max_mem: 2179M\n",
            "\u001b[32m[06/14 03:15:49 d2.utils.events]: \u001b[0m eta: 0:11:48  iter: 59  total_loss: 1.821  loss_cls: 0.984  loss_box_reg: 0.02958  loss_mask: 0.6805  loss_rpn_cls: 0.08739  loss_rpn_loc: 0.009726  total_val_loss: 1.825  val_loss_cls: 0.9781  val_loss_box_reg: 0.04097  val_loss_mask: 0.6771  val_loss_rpn_cls: 0.1053  val_loss_rpn_loc: 0.01381  time: 0.1672  data_time: 0.0099  lr: 1.4985e-05  max_mem: 2179M\n",
            "\u001b[32m[06/14 03:15:54 d2.utils.events]: \u001b[0m eta: 0:11:32  iter: 79  total_loss: 1.464  loss_cls: 0.6394  loss_box_reg: 0.08369  loss_mask: 0.6635  loss_rpn_cls: 0.08073  loss_rpn_loc: 0.01183  total_val_loss: 1.486  val_loss_cls: 0.6743  val_loss_box_reg: 0.07399  val_loss_mask: 0.6642  val_loss_rpn_cls: 0.06352  val_loss_rpn_loc: 0.0102  time: 0.1640  data_time: 0.0173  lr: 1.998e-05  max_mem: 2179M\n",
            "\u001b[32m[06/14 03:15:59 d2.utils.events]: \u001b[0m eta: 0:11:25  iter: 99  total_loss: 1.251  loss_cls: 0.4259  loss_box_reg: 0.0763  loss_mask: 0.6525  loss_rpn_cls: 0.06256  loss_rpn_loc: 0.007661  total_val_loss: 1.249  val_loss_cls: 0.45  val_loss_box_reg: 0.08451  val_loss_mask: 0.6413  val_loss_rpn_cls: 0.06018  val_loss_rpn_loc: 0.00793  time: 0.1633  data_time: 0.0188  lr: 2.4975e-05  max_mem: 2179M\n",
            "\u001b[32m[06/14 03:16:04 d2.utils.events]: \u001b[0m eta: 0:11:26  iter: 119  total_loss: 1.155  loss_cls: 0.3425  loss_box_reg: 0.1143  loss_mask: 0.6351  loss_rpn_cls: 0.04728  loss_rpn_loc: 0.008818  total_val_loss: 1.138  val_loss_cls: 0.3304  val_loss_box_reg: 0.1247  val_loss_mask: 0.6234  val_loss_rpn_cls: 0.04436  val_loss_rpn_loc: 0.01088  time: 0.1650  data_time: 0.0195  lr: 2.997e-05  max_mem: 2179M\n",
            "\u001b[32m[06/14 03:16:09 d2.utils.events]: \u001b[0m eta: 0:11:27  iter: 139  total_loss: 1.07  loss_cls: 0.2828  loss_box_reg: 0.1143  loss_mask: 0.6088  loss_rpn_cls: 0.0419  loss_rpn_loc: 0.01001  total_val_loss: 1.101  val_loss_cls: 0.2641  val_loss_box_reg: 0.1615  val_loss_mask: 0.6117  val_loss_rpn_cls: 0.03139  val_loss_rpn_loc: 0.009452  time: 0.1666  data_time: 0.0211  lr: 3.4965e-05  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:16:15 d2.utils.events]: \u001b[0m eta: 0:11:28  iter: 159  total_loss: 1.075  loss_cls: 0.2641  loss_box_reg: 0.1823  loss_mask: 0.588  loss_rpn_cls: 0.04166  loss_rpn_loc: 0.008878  total_val_loss: 1.138  val_loss_cls: 0.2613  val_loss_box_reg: 0.1893  val_loss_mask: 0.5898  val_loss_rpn_cls: 0.03366  val_loss_rpn_loc: 0.009045  time: 0.1678  data_time: 0.0260  lr: 3.996e-05  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:16:20 d2.utils.events]: \u001b[0m eta: 0:11:21  iter: 179  total_loss: 1.054  loss_cls: 0.2522  loss_box_reg: 0.2022  loss_mask: 0.5586  loss_rpn_cls: 0.02019  loss_rpn_loc: 0.008916  total_val_loss: 1.061  val_loss_cls: 0.249  val_loss_box_reg: 0.2202  val_loss_mask: 0.5531  val_loss_rpn_cls: 0.02957  val_loss_rpn_loc: 0.008446  time: 0.1683  data_time: 0.0195  lr: 4.4955e-05  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:16:26 d2.utils.events]: \u001b[0m eta: 0:11:14  iter: 199  total_loss: 1.042  loss_cls: 0.2396  loss_box_reg: 0.2639  loss_mask: 0.5343  loss_rpn_cls: 0.01537  loss_rpn_loc: 0.00656  total_val_loss: 1.036  val_loss_cls: 0.2314  val_loss_box_reg: 0.2513  val_loss_mask: 0.5238  val_loss_rpn_cls: 0.01434  val_loss_rpn_loc: 0.007764  time: 0.1676  data_time: 0.0156  lr: 4.995e-05  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:16:31 d2.utils.events]: \u001b[0m eta: 0:11:11  iter: 219  total_loss: 1.012  loss_cls: 0.2328  loss_box_reg: 0.2567  loss_mask: 0.4912  loss_rpn_cls: 0.01381  loss_rpn_loc: 0.007095  total_val_loss: 0.9941  val_loss_cls: 0.209  val_loss_box_reg: 0.2503  val_loss_mask: 0.4974  val_loss_rpn_cls: 0.01434  val_loss_rpn_loc: 0.009887  time: 0.1672  data_time: 0.0169  lr: 5.4945e-05  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:16:37 d2.utils.events]: \u001b[0m eta: 0:11:11  iter: 239  total_loss: 1.017  loss_cls: 0.2211  loss_box_reg: 0.2434  loss_mask: 0.4937  loss_rpn_cls: 0.02405  loss_rpn_loc: 0.007776  total_val_loss: 0.9363  val_loss_cls: 0.2301  val_loss_box_reg: 0.2745  val_loss_mask: 0.4535  val_loss_rpn_cls: 0.01143  val_loss_rpn_loc: 0.006914  time: 0.1690  data_time: 0.0329  lr: 5.994e-05  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:16:42 d2.utils.events]: \u001b[0m eta: 0:11:08  iter: 259  total_loss: 0.897  loss_cls: 0.1961  loss_box_reg: 0.2494  loss_mask: 0.4466  loss_rpn_cls: 0.006822  loss_rpn_loc: 0.005319  total_val_loss: 0.9696  val_loss_cls: 0.219  val_loss_box_reg: 0.2811  val_loss_mask: 0.4412  val_loss_rpn_cls: 0.007299  val_loss_rpn_loc: 0.006468  time: 0.1683  data_time: 0.0087  lr: 6.4935e-05  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:16:47 d2.utils.events]: \u001b[0m eta: 0:11:08  iter: 279  total_loss: 1.054  loss_cls: 0.2305  loss_box_reg: 0.3108  loss_mask: 0.4521  loss_rpn_cls: 0.01264  loss_rpn_loc: 0.006205  total_val_loss: 0.9215  val_loss_cls: 0.215  val_loss_box_reg: 0.2887  val_loss_mask: 0.4187  val_loss_rpn_cls: 0.01052  val_loss_rpn_loc: 0.004696  time: 0.1679  data_time: 0.0097  lr: 6.993e-05  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:16:52 d2.utils.events]: \u001b[0m eta: 0:11:07  iter: 299  total_loss: 0.9634  loss_cls: 0.2127  loss_box_reg: 0.3196  loss_mask: 0.4107  loss_rpn_cls: 0.00984  loss_rpn_loc: 0.005543  total_val_loss: 0.9598  val_loss_cls: 0.2286  val_loss_box_reg: 0.3078  val_loss_mask: 0.4269  val_loss_rpn_cls: 0.008776  val_loss_rpn_loc: 0.007355  time: 0.1679  data_time: 0.0141  lr: 7.4925e-05  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:16:57 d2.utils.events]: \u001b[0m eta: 0:11:05  iter: 319  total_loss: 0.9648  loss_cls: 0.2264  loss_box_reg: 0.3275  loss_mask: 0.3772  loss_rpn_cls: 0.006274  loss_rpn_loc: 0.006504  total_val_loss: 0.8008  val_loss_cls: 0.1858  val_loss_box_reg: 0.2946  val_loss_mask: 0.3537  val_loss_rpn_cls: 0.004104  val_loss_rpn_loc: 0.004549  time: 0.1683  data_time: 0.0202  lr: 7.992e-05  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:17:03 d2.utils.events]: \u001b[0m eta: 0:11:01  iter: 339  total_loss: 0.8322  loss_cls: 0.1978  loss_box_reg: 0.2687  loss_mask: 0.3649  loss_rpn_cls: 0.01619  loss_rpn_loc: 0.007911  total_val_loss: 0.9785  val_loss_cls: 0.2222  val_loss_box_reg: 0.3359  val_loss_mask: 0.3788  val_loss_rpn_cls: 0.00584  val_loss_rpn_loc: 0.006406  time: 0.1686  data_time: 0.0203  lr: 8.4915e-05  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:17:08 d2.utils.events]: \u001b[0m eta: 0:10:59  iter: 359  total_loss: 0.9089  loss_cls: 0.2146  loss_box_reg: 0.3456  loss_mask: 0.3567  loss_rpn_cls: 0.007343  loss_rpn_loc: 0.005366  total_val_loss: 0.8646  val_loss_cls: 0.1986  val_loss_box_reg: 0.3017  val_loss_mask: 0.3375  val_loss_rpn_cls: 0.007107  val_loss_rpn_loc: 0.005517  time: 0.1690  data_time: 0.0158  lr: 8.991e-05  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:17:14 d2.utils.events]: \u001b[0m eta: 0:10:55  iter: 379  total_loss: 0.8894  loss_cls: 0.2146  loss_box_reg: 0.2962  loss_mask: 0.3156  loss_rpn_cls: 0.008077  loss_rpn_loc: 0.005614  total_val_loss: 0.8495  val_loss_cls: 0.2003  val_loss_box_reg: 0.3238  val_loss_mask: 0.3282  val_loss_rpn_cls: 0.007332  val_loss_rpn_loc: 0.003993  time: 0.1691  data_time: 0.0205  lr: 9.4905e-05  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:17:19 d2.utils.events]: \u001b[0m eta: 0:10:53  iter: 399  total_loss: 0.8951  loss_cls: 0.2165  loss_box_reg: 0.3214  loss_mask: 0.2816  loss_rpn_cls: 0.004475  loss_rpn_loc: 0.005547  total_val_loss: 0.7707  val_loss_cls: 0.199  val_loss_box_reg: 0.3259  val_loss_mask: 0.3009  val_loss_rpn_cls: 0.005  val_loss_rpn_loc: 0.005341  time: 0.1692  data_time: 0.0151  lr: 9.99e-05  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:17:24 d2.utils.events]: \u001b[0m eta: 0:10:49  iter: 419  total_loss: 0.8548  loss_cls: 0.2104  loss_box_reg: 0.323  loss_mask: 0.2965  loss_rpn_cls: 0.01243  loss_rpn_loc: 0.005732  total_val_loss: 0.7706  val_loss_cls: 0.204  val_loss_box_reg: 0.3149  val_loss_mask: 0.282  val_loss_rpn_cls: 0.002566  val_loss_rpn_loc: 0.0051  time: 0.1695  data_time: 0.0241  lr: 0.0001049  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:17:30 d2.utils.events]: \u001b[0m eta: 0:10:47  iter: 439  total_loss: 0.8168  loss_cls: 0.219  loss_box_reg: 0.3421  loss_mask: 0.2414  loss_rpn_cls: 0.008888  loss_rpn_loc: 0.006843  total_val_loss: 0.7932  val_loss_cls: 0.2012  val_loss_box_reg: 0.3102  val_loss_mask: 0.2469  val_loss_rpn_cls: 0.008408  val_loss_rpn_loc: 0.004581  time: 0.1700  data_time: 0.0221  lr: 0.00010989  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:17:35 d2.utils.events]: \u001b[0m eta: 0:10:44  iter: 459  total_loss: 0.7798  loss_cls: 0.2057  loss_box_reg: 0.339  loss_mask: 0.2217  loss_rpn_cls: 0.007035  loss_rpn_loc: 0.005389  total_val_loss: 0.7429  val_loss_cls: 0.1983  val_loss_box_reg: 0.3219  val_loss_mask: 0.2461  val_loss_rpn_cls: 0.004597  val_loss_rpn_loc: 0.005234  time: 0.1699  data_time: 0.0122  lr: 0.00011489  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:17:40 d2.utils.events]: \u001b[0m eta: 0:10:42  iter: 479  total_loss: 0.7975  loss_cls: 0.1978  loss_box_reg: 0.3394  loss_mask: 0.2238  loss_rpn_cls: 0.0045  loss_rpn_loc: 0.005685  total_val_loss: 0.8544  val_loss_cls: 0.2293  val_loss_box_reg: 0.3434  val_loss_mask: 0.2322  val_loss_rpn_cls: 0.005018  val_loss_rpn_loc: 0.00666  time: 0.1697  data_time: 0.0085  lr: 0.00011988  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:17:45 d2.utils.events]: \u001b[0m eta: 0:10:38  iter: 499  total_loss: 0.7394  loss_cls: 0.2072  loss_box_reg: 0.3085  loss_mask: 0.1854  loss_rpn_cls: 0.003933  loss_rpn_loc: 0.006  total_val_loss: 0.7688  val_loss_cls: 0.21  val_loss_box_reg: 0.3454  val_loss_mask: 0.2223  val_loss_rpn_cls: 0.005058  val_loss_rpn_loc: 0.006156  time: 0.1695  data_time: 0.0109  lr: 0.00012488  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:17:51 d2.utils.events]: \u001b[0m eta: 0:10:36  iter: 519  total_loss: 0.7275  loss_cls: 0.1888  loss_box_reg: 0.3086  loss_mask: 0.2023  loss_rpn_cls: 0.002104  loss_rpn_loc: 0.005346  total_val_loss: 0.7664  val_loss_cls: 0.1875  val_loss_box_reg: 0.325  val_loss_mask: 0.239  val_loss_rpn_cls: 0.003076  val_loss_rpn_loc: 0.005703  time: 0.1698  data_time: 0.0236  lr: 0.00012987  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:17:56 d2.utils.events]: \u001b[0m eta: 0:10:36  iter: 539  total_loss: 0.8135  loss_cls: 0.2001  loss_box_reg: 0.3263  loss_mask: 0.2219  loss_rpn_cls: 0.003759  loss_rpn_loc: 0.004617  total_val_loss: 0.7497  val_loss_cls: 0.2154  val_loss_box_reg: 0.348  val_loss_mask: 0.2024  val_loss_rpn_cls: 0.002804  val_loss_rpn_loc: 0.00591  time: 0.1701  data_time: 0.0188  lr: 0.00013487  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:18:02 d2.utils.events]: \u001b[0m eta: 0:10:34  iter: 559  total_loss: 0.7563  loss_cls: 0.1946  loss_box_reg: 0.3168  loss_mask: 0.2448  loss_rpn_cls: 0.0009776  loss_rpn_loc: 0.007321  total_val_loss: 0.6552  val_loss_cls: 0.1748  val_loss_box_reg: 0.2814  val_loss_mask: 0.2356  val_loss_rpn_cls: 0.006945  val_loss_rpn_loc: 0.006326  time: 0.1703  data_time: 0.0161  lr: 0.00013986  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:18:07 d2.utils.events]: \u001b[0m eta: 0:10:35  iter: 579  total_loss: 0.8201  loss_cls: 0.2395  loss_box_reg: 0.3663  loss_mask: 0.202  loss_rpn_cls: 0.004296  loss_rpn_loc: 0.006554  total_val_loss: 0.7756  val_loss_cls: 0.2063  val_loss_box_reg: 0.308  val_loss_mask: 0.1668  val_loss_rpn_cls: 0.001832  val_loss_rpn_loc: 0.005976  time: 0.1709  data_time: 0.0234  lr: 0.00014486  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:18:12 d2.utils.events]: \u001b[0m eta: 0:10:34  iter: 599  total_loss: 0.7507  loss_cls: 0.2044  loss_box_reg: 0.3247  loss_mask: 0.1805  loss_rpn_cls: 0.004372  loss_rpn_loc: 0.006486  total_val_loss: 0.7031  val_loss_cls: 0.188  val_loss_box_reg: 0.309  val_loss_mask: 0.1706  val_loss_rpn_cls: 0.002905  val_loss_rpn_loc: 0.005989  time: 0.1710  data_time: 0.0138  lr: 0.00014985  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:18:18 d2.utils.events]: \u001b[0m eta: 0:10:31  iter: 619  total_loss: 0.7849  loss_cls: 0.2019  loss_box_reg: 0.3163  loss_mask: 0.2083  loss_rpn_cls: 0.002554  loss_rpn_loc: 0.009352  total_val_loss: 0.7613  val_loss_cls: 0.2279  val_loss_box_reg: 0.317  val_loss_mask: 0.1797  val_loss_rpn_cls: 0.0005331  val_loss_rpn_loc: 0.006744  time: 0.1710  data_time: 0.0127  lr: 0.00015485  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:18:23 d2.utils.events]: \u001b[0m eta: 0:10:28  iter: 639  total_loss: 0.7869  loss_cls: 0.2395  loss_box_reg: 0.3273  loss_mask: 0.2146  loss_rpn_cls: 0.004286  loss_rpn_loc: 0.008514  total_val_loss: 0.698  val_loss_cls: 0.1863  val_loss_box_reg: 0.2528  val_loss_mask: 0.1894  val_loss_rpn_cls: 0.005505  val_loss_rpn_loc: 0.005622  time: 0.1712  data_time: 0.0140  lr: 0.00015984  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:18:29 d2.utils.events]: \u001b[0m eta: 0:10:25  iter: 659  total_loss: 0.7015  loss_cls: 0.2018  loss_box_reg: 0.2855  loss_mask: 0.1944  loss_rpn_cls: 0.001449  loss_rpn_loc: 0.007347  total_val_loss: 0.6967  val_loss_cls: 0.2073  val_loss_box_reg: 0.2911  val_loss_mask: 0.2055  val_loss_rpn_cls: 0.001504  val_loss_rpn_loc: 0.005648  time: 0.1711  data_time: 0.0114  lr: 0.00016484  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:18:34 d2.utils.events]: \u001b[0m eta: 0:10:23  iter: 679  total_loss: 0.7431  loss_cls: 0.2148  loss_box_reg: 0.2748  loss_mask: 0.2067  loss_rpn_cls: 0.01108  loss_rpn_loc: 0.007838  total_val_loss: 0.6379  val_loss_cls: 0.2096  val_loss_box_reg: 0.2742  val_loss_mask: 0.1713  val_loss_rpn_cls: 0.002261  val_loss_rpn_loc: 0.006602  time: 0.1711  data_time: 0.0101  lr: 0.00016983  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:18:39 d2.utils.events]: \u001b[0m eta: 0:10:21  iter: 699  total_loss: 0.6892  loss_cls: 0.2275  loss_box_reg: 0.293  loss_mask: 0.2094  loss_rpn_cls: 0.002205  loss_rpn_loc: 0.007148  total_val_loss: 0.6117  val_loss_cls: 0.1912  val_loss_box_reg: 0.2019  val_loss_mask: 0.1888  val_loss_rpn_cls: 0.002834  val_loss_rpn_loc: 0.006623  time: 0.1713  data_time: 0.0140  lr: 0.00017483  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:18:45 d2.utils.events]: \u001b[0m eta: 0:10:19  iter: 719  total_loss: 0.7173  loss_cls: 0.2225  loss_box_reg: 0.256  loss_mask: 0.2068  loss_rpn_cls: 0.001148  loss_rpn_loc: 0.006855  total_val_loss: 0.5649  val_loss_cls: 0.188  val_loss_box_reg: 0.2219  val_loss_mask: 0.1857  val_loss_rpn_cls: 0.001539  val_loss_rpn_loc: 0.00495  time: 0.1716  data_time: 0.0156  lr: 0.00017982  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:18:50 d2.utils.events]: \u001b[0m eta: 0:10:16  iter: 739  total_loss: 0.6425  loss_cls: 0.1732  loss_box_reg: 0.1921  loss_mask: 0.1748  loss_rpn_cls: 0.003905  loss_rpn_loc: 0.007381  total_val_loss: 0.5557  val_loss_cls: 0.1819  val_loss_box_reg: 0.2005  val_loss_mask: 0.1502  val_loss_rpn_cls: 0.0007256  val_loss_rpn_loc: 0.006559  time: 0.1715  data_time: 0.0115  lr: 0.00018482  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:18:56 d2.utils.events]: \u001b[0m eta: 0:10:13  iter: 759  total_loss: 0.6252  loss_cls: 0.1791  loss_box_reg: 0.2512  loss_mask: 0.1821  loss_rpn_cls: 0.001019  loss_rpn_loc: 0.006271  total_val_loss: 0.5996  val_loss_cls: 0.1784  val_loss_box_reg: 0.2279  val_loss_mask: 0.1871  val_loss_rpn_cls: 0.00151  val_loss_rpn_loc: 0.005404  time: 0.1718  data_time: 0.0163  lr: 0.00018981  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:19:01 d2.utils.events]: \u001b[0m eta: 0:10:10  iter: 779  total_loss: 0.5934  loss_cls: 0.1957  loss_box_reg: 0.1957  loss_mask: 0.2028  loss_rpn_cls: 0.00155  loss_rpn_loc: 0.007828  total_val_loss: 0.6468  val_loss_cls: 0.1966  val_loss_box_reg: 0.2537  val_loss_mask: 0.2116  val_loss_rpn_cls: 0.002904  val_loss_rpn_loc: 0.007161  time: 0.1717  data_time: 0.0106  lr: 0.00019481  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:19:06 d2.utils.events]: \u001b[0m eta: 0:10:07  iter: 799  total_loss: 0.6111  loss_cls: 0.1802  loss_box_reg: 0.2067  loss_mask: 0.1979  loss_rpn_cls: 0.001964  loss_rpn_loc: 0.005468  total_val_loss: 0.5575  val_loss_cls: 0.181  val_loss_box_reg: 0.1842  val_loss_mask: 0.1592  val_loss_rpn_cls: 0.0005294  val_loss_rpn_loc: 0.005754  time: 0.1716  data_time: 0.0117  lr: 0.0001998  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:19:12 d2.utils.events]: \u001b[0m eta: 0:10:04  iter: 819  total_loss: 0.5491  loss_cls: 0.1988  loss_box_reg: 0.174  loss_mask: 0.1503  loss_rpn_cls: 0.0005685  loss_rpn_loc: 0.005625  total_val_loss: 0.4776  val_loss_cls: 0.1468  val_loss_box_reg: 0.1631  val_loss_mask: 0.1675  val_loss_rpn_cls: 0.002124  val_loss_rpn_loc: 0.005938  time: 0.1715  data_time: 0.0092  lr: 0.0002048  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:19:17 d2.utils.events]: \u001b[0m eta: 0:10:00  iter: 839  total_loss: 0.5547  loss_cls: 0.179  loss_box_reg: 0.193  loss_mask: 0.159  loss_rpn_cls: 0.002565  loss_rpn_loc: 0.005248  total_val_loss: 0.5947  val_loss_cls: 0.1882  val_loss_box_reg: 0.2069  val_loss_mask: 0.188  val_loss_rpn_cls: 0.001584  val_loss_rpn_loc: 0.007708  time: 0.1713  data_time: 0.0100  lr: 0.00020979  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:19:22 d2.utils.events]: \u001b[0m eta: 0:09:57  iter: 859  total_loss: 0.5393  loss_cls: 0.1759  loss_box_reg: 0.1649  loss_mask: 0.1713  loss_rpn_cls: 0.003376  loss_rpn_loc: 0.006422  total_val_loss: 0.5069  val_loss_cls: 0.1691  val_loss_box_reg: 0.1509  val_loss_mask: 0.14  val_loss_rpn_cls: 0.001342  val_loss_rpn_loc: 0.006065  time: 0.1712  data_time: 0.0097  lr: 0.00021479  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:19:27 d2.utils.events]: \u001b[0m eta: 0:09:54  iter: 879  total_loss: 0.5641  loss_cls: 0.1849  loss_box_reg: 0.1976  loss_mask: 0.1767  loss_rpn_cls: 0.00234  loss_rpn_loc: 0.006107  total_val_loss: 0.5154  val_loss_cls: 0.1739  val_loss_box_reg: 0.1694  val_loss_mask: 0.1453  val_loss_rpn_cls: 0.000468  val_loss_rpn_loc: 0.005113  time: 0.1712  data_time: 0.0118  lr: 0.00021978  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:19:33 d2.utils.events]: \u001b[0m eta: 0:09:50  iter: 899  total_loss: 0.453  loss_cls: 0.1694  loss_box_reg: 0.1562  loss_mask: 0.138  loss_rpn_cls: 0.001136  loss_rpn_loc: 0.005235  total_val_loss: 0.6343  val_loss_cls: 0.1784  val_loss_box_reg: 0.1969  val_loss_mask: 0.197  val_loss_rpn_cls: 0.002297  val_loss_rpn_loc: 0.00618  time: 0.1710  data_time: 0.0176  lr: 0.00022478  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:19:38 d2.utils.events]: \u001b[0m eta: 0:09:46  iter: 919  total_loss: 0.456  loss_cls: 0.1567  loss_box_reg: 0.1365  loss_mask: 0.1368  loss_rpn_cls: 0.002407  loss_rpn_loc: 0.004414  total_val_loss: 0.49  val_loss_cls: 0.1603  val_loss_box_reg: 0.1587  val_loss_mask: 0.1746  val_loss_rpn_cls: 0.001104  val_loss_rpn_loc: 0.005211  time: 0.1709  data_time: 0.0124  lr: 0.00022977  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:19:43 d2.utils.events]: \u001b[0m eta: 0:09:43  iter: 939  total_loss: 0.4905  loss_cls: 0.1693  loss_box_reg: 0.1555  loss_mask: 0.1675  loss_rpn_cls: 0.0007163  loss_rpn_loc: 0.004716  total_val_loss: 0.4461  val_loss_cls: 0.1338  val_loss_box_reg: 0.133  val_loss_mask: 0.1691  val_loss_rpn_cls: 0.0003645  val_loss_rpn_loc: 0.004104  time: 0.1709  data_time: 0.0185  lr: 0.00023477  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:19:48 d2.utils.events]: \u001b[0m eta: 0:09:39  iter: 959  total_loss: 0.4627  loss_cls: 0.148  loss_box_reg: 0.1467  loss_mask: 0.1331  loss_rpn_cls: 0.001894  loss_rpn_loc: 0.005062  total_val_loss: 0.5759  val_loss_cls: 0.1512  val_loss_box_reg: 0.2079  val_loss_mask: 0.1833  val_loss_rpn_cls: 0.0007615  val_loss_rpn_loc: 0.00598  time: 0.1708  data_time: 0.0111  lr: 0.00023976  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:19:54 d2.utils.events]: \u001b[0m eta: 0:09:37  iter: 979  total_loss: 0.4925  loss_cls: 0.1767  loss_box_reg: 0.1612  loss_mask: 0.1697  loss_rpn_cls: 0.001919  loss_rpn_loc: 0.00506  total_val_loss: 0.5543  val_loss_cls: 0.1558  val_loss_box_reg: 0.1646  val_loss_mask: 0.1765  val_loss_rpn_cls: 0.001254  val_loss_rpn_loc: 0.004718  time: 0.1712  data_time: 0.0186  lr: 0.00024476  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:19:59 d2.utils.events]: \u001b[0m eta: 0:09:34  iter: 999  total_loss: 0.61  loss_cls: 0.1868  loss_box_reg: 0.2168  loss_mask: 0.1752  loss_rpn_cls: 0.00194  loss_rpn_loc: 0.00667  total_val_loss: 0.4313  val_loss_cls: 0.1452  val_loss_box_reg: 0.1536  val_loss_mask: 0.1177  val_loss_rpn_cls: 0.0009341  val_loss_rpn_loc: 0.003908  time: 0.1714  data_time: 0.0152  lr: 0.00024975  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:20:05 d2.utils.events]: \u001b[0m eta: 0:09:29  iter: 1019  total_loss: 0.4733  loss_cls: 0.1508  loss_box_reg: 0.1709  loss_mask: 0.1551  loss_rpn_cls: 0.0005473  loss_rpn_loc: 0.004641  total_val_loss: 0.5352  val_loss_cls: 0.1496  val_loss_box_reg: 0.1576  val_loss_mask: 0.2022  val_loss_rpn_cls: 0.0009305  val_loss_rpn_loc: 0.004826  time: 0.1712  data_time: 0.0099  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:20:10 d2.utils.events]: \u001b[0m eta: 0:09:27  iter: 1039  total_loss: 0.4332  loss_cls: 0.143  loss_box_reg: 0.1486  loss_mask: 0.1328  loss_rpn_cls: 0.0009786  loss_rpn_loc: 0.00702  total_val_loss: 0.4179  val_loss_cls: 0.1374  val_loss_box_reg: 0.1371  val_loss_mask: 0.131  val_loss_rpn_cls: 0.0003355  val_loss_rpn_loc: 0.004509  time: 0.1712  data_time: 0.0130  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:20:15 d2.utils.events]: \u001b[0m eta: 0:09:23  iter: 1059  total_loss: 0.4544  loss_cls: 0.1618  loss_box_reg: 0.1653  loss_mask: 0.1474  loss_rpn_cls: 0.001008  loss_rpn_loc: 0.006001  total_val_loss: 0.4842  val_loss_cls: 0.1671  val_loss_box_reg: 0.1564  val_loss_mask: 0.1578  val_loss_rpn_cls: 0.0008723  val_loss_rpn_loc: 0.004252  time: 0.1710  data_time: 0.0091  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:20:21 d2.utils.events]: \u001b[0m eta: 0:09:21  iter: 1079  total_loss: 0.5057  loss_cls: 0.1533  loss_box_reg: 0.1448  loss_mask: 0.1423  loss_rpn_cls: 0.0003904  loss_rpn_loc: 0.005916  total_val_loss: 0.5339  val_loss_cls: 0.1735  val_loss_box_reg: 0.1585  val_loss_mask: 0.1595  val_loss_rpn_cls: 0.002646  val_loss_rpn_loc: 0.003832  time: 0.1712  data_time: 0.0178  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:20:26 d2.utils.events]: \u001b[0m eta: 0:09:18  iter: 1099  total_loss: 0.4967  loss_cls: 0.1412  loss_box_reg: 0.1885  loss_mask: 0.169  loss_rpn_cls: 0.002356  loss_rpn_loc: 0.005986  total_val_loss: 0.4393  val_loss_cls: 0.1268  val_loss_box_reg: 0.1363  val_loss_mask: 0.1446  val_loss_rpn_cls: 0.001717  val_loss_rpn_loc: 0.003859  time: 0.1712  data_time: 0.0123  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:20:31 d2.utils.events]: \u001b[0m eta: 0:09:16  iter: 1119  total_loss: 0.4615  loss_cls: 0.1422  loss_box_reg: 0.1594  loss_mask: 0.1591  loss_rpn_cls: 0.001848  loss_rpn_loc: 0.00422  total_val_loss: 0.4217  val_loss_cls: 0.1399  val_loss_box_reg: 0.118  val_loss_mask: 0.1389  val_loss_rpn_cls: 0.0005386  val_loss_rpn_loc: 0.004308  time: 0.1713  data_time: 0.0176  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:20:37 d2.utils.events]: \u001b[0m eta: 0:09:14  iter: 1139  total_loss: 0.4489  loss_cls: 0.1445  loss_box_reg: 0.1534  loss_mask: 0.1361  loss_rpn_cls: 0.0009178  loss_rpn_loc: 0.005119  total_val_loss: 0.3827  val_loss_cls: 0.1197  val_loss_box_reg: 0.1186  val_loss_mask: 0.1455  val_loss_rpn_cls: 0.0003375  val_loss_rpn_loc: 0.003758  time: 0.1716  data_time: 0.0189  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:20:42 d2.utils.events]: \u001b[0m eta: 0:09:10  iter: 1159  total_loss: 0.4318  loss_cls: 0.1402  loss_box_reg: 0.1431  loss_mask: 0.1443  loss_rpn_cls: 0.0002698  loss_rpn_loc: 0.00389  total_val_loss: 0.4189  val_loss_cls: 0.1407  val_loss_box_reg: 0.1434  val_loss_mask: 0.1299  val_loss_rpn_cls: 0.0002073  val_loss_rpn_loc: 0.003742  time: 0.1717  data_time: 0.0131  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:20:48 d2.utils.events]: \u001b[0m eta: 0:09:07  iter: 1179  total_loss: 0.3919  loss_cls: 0.1339  loss_box_reg: 0.1299  loss_mask: 0.1443  loss_rpn_cls: 0.0004275  loss_rpn_loc: 0.004685  total_val_loss: 0.41  val_loss_cls: 0.134  val_loss_box_reg: 0.1162  val_loss_mask: 0.1714  val_loss_rpn_cls: 0.0007726  val_loss_rpn_loc: 0.00455  time: 0.1716  data_time: 0.0088  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:20:53 d2.utils.events]: \u001b[0m eta: 0:09:04  iter: 1199  total_loss: 0.4673  loss_cls: 0.1189  loss_box_reg: 0.1557  loss_mask: 0.1899  loss_rpn_cls: 0.002705  loss_rpn_loc: 0.004899  total_val_loss: 0.5289  val_loss_cls: 0.1231  val_loss_box_reg: 0.2026  val_loss_mask: 0.1817  val_loss_rpn_cls: 0.0007047  val_loss_rpn_loc: 0.004743  time: 0.1716  data_time: 0.0098  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:20:59 d2.utils.events]: \u001b[0m eta: 0:09:03  iter: 1219  total_loss: 0.3928  loss_cls: 0.1335  loss_box_reg: 0.1228  loss_mask: 0.1185  loss_rpn_cls: 0.0006505  loss_rpn_loc: 0.004282  total_val_loss: 0.3477  val_loss_cls: 0.1074  val_loss_box_reg: 0.1049  val_loss_mask: 0.142  val_loss_rpn_cls: 0.001076  val_loss_rpn_loc: 0.00486  time: 0.1717  data_time: 0.0139  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:21:04 d2.utils.events]: \u001b[0m eta: 0:08:59  iter: 1239  total_loss: 0.3658  loss_cls: 0.127  loss_box_reg: 0.1132  loss_mask: 0.1359  loss_rpn_cls: 0.00135  loss_rpn_loc: 0.003716  total_val_loss: 0.4922  val_loss_cls: 0.1423  val_loss_box_reg: 0.1618  val_loss_mask: 0.1767  val_loss_rpn_cls: 0.0007638  val_loss_rpn_loc: 0.005626  time: 0.1718  data_time: 0.0130  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:21:10 d2.utils.events]: \u001b[0m eta: 0:08:56  iter: 1259  total_loss: 0.4295  loss_cls: 0.1301  loss_box_reg: 0.1443  loss_mask: 0.1242  loss_rpn_cls: 0.000506  loss_rpn_loc: 0.004562  total_val_loss: 0.5297  val_loss_cls: 0.1562  val_loss_box_reg: 0.1598  val_loss_mask: 0.1768  val_loss_rpn_cls: 0.002275  val_loss_rpn_loc: 0.005064  time: 0.1717  data_time: 0.0109  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:21:15 d2.utils.events]: \u001b[0m eta: 0:08:53  iter: 1279  total_loss: 0.3146  loss_cls: 0.126  loss_box_reg: 0.1152  loss_mask: 0.1021  loss_rpn_cls: 0.0003663  loss_rpn_loc: 0.004024  total_val_loss: 0.3692  val_loss_cls: 0.1184  val_loss_box_reg: 0.1134  val_loss_mask: 0.1146  val_loss_rpn_cls: 0.0002049  val_loss_rpn_loc: 0.003599  time: 0.1716  data_time: 0.0095  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:21:20 d2.utils.events]: \u001b[0m eta: 0:08:50  iter: 1299  total_loss: 0.4393  loss_cls: 0.1389  loss_box_reg: 0.1525  loss_mask: 0.135  loss_rpn_cls: 0.000808  loss_rpn_loc: 0.005025  total_val_loss: 0.4329  val_loss_cls: 0.1355  val_loss_box_reg: 0.1375  val_loss_mask: 0.1337  val_loss_rpn_cls: 0.0005834  val_loss_rpn_loc: 0.004994  time: 0.1717  data_time: 0.0180  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:21:26 d2.utils.events]: \u001b[0m eta: 0:08:46  iter: 1319  total_loss: 0.3949  loss_cls: 0.1244  loss_box_reg: 0.1375  loss_mask: 0.1498  loss_rpn_cls: 0.0008897  loss_rpn_loc: 0.004679  total_val_loss: 0.4711  val_loss_cls: 0.1537  val_loss_box_reg: 0.1397  val_loss_mask: 0.1492  val_loss_rpn_cls: 0.0008026  val_loss_rpn_loc: 0.004711  time: 0.1716  data_time: 0.0105  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:21:31 d2.utils.events]: \u001b[0m eta: 0:08:43  iter: 1339  total_loss: 0.4373  loss_cls: 0.1381  loss_box_reg: 0.139  loss_mask: 0.1655  loss_rpn_cls: 0.00124  loss_rpn_loc: 0.005119  total_val_loss: 0.3881  val_loss_cls: 0.1212  val_loss_box_reg: 0.1094  val_loss_mask: 0.1421  val_loss_rpn_cls: 0.0003729  val_loss_rpn_loc: 0.004487  time: 0.1716  data_time: 0.0132  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:21:37 d2.utils.events]: \u001b[0m eta: 0:08:40  iter: 1359  total_loss: 0.5051  loss_cls: 0.1472  loss_box_reg: 0.1893  loss_mask: 0.1348  loss_rpn_cls: 0.001294  loss_rpn_loc: 0.006422  total_val_loss: 0.3819  val_loss_cls: 0.1478  val_loss_box_reg: 0.1114  val_loss_mask: 0.1362  val_loss_rpn_cls: 0.00103  val_loss_rpn_loc: 0.005168  time: 0.1717  data_time: 0.0136  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:21:42 d2.utils.events]: \u001b[0m eta: 0:08:37  iter: 1379  total_loss: 0.3381  loss_cls: 0.1016  loss_box_reg: 0.1175  loss_mask: 0.1068  loss_rpn_cls: 0.002223  loss_rpn_loc: 0.003134  total_val_loss: 0.4623  val_loss_cls: 0.1292  val_loss_box_reg: 0.1354  val_loss_mask: 0.1652  val_loss_rpn_cls: 0.001207  val_loss_rpn_loc: 0.004899  time: 0.1716  data_time: 0.0106  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:21:47 d2.utils.events]: \u001b[0m eta: 0:08:33  iter: 1399  total_loss: 0.3479  loss_cls: 0.1207  loss_box_reg: 0.095  loss_mask: 0.1254  loss_rpn_cls: 0.00103  loss_rpn_loc: 0.004335  total_val_loss: 0.3861  val_loss_cls: 0.1256  val_loss_box_reg: 0.1091  val_loss_mask: 0.1397  val_loss_rpn_cls: 0.0007992  val_loss_rpn_loc: 0.003797  time: 0.1715  data_time: 0.0075  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:21:52 d2.utils.events]: \u001b[0m eta: 0:08:31  iter: 1419  total_loss: 0.4274  loss_cls: 0.1381  loss_box_reg: 0.146  loss_mask: 0.1302  loss_rpn_cls: 0.0003329  loss_rpn_loc: 0.004882  total_val_loss: 0.4254  val_loss_cls: 0.1451  val_loss_box_reg: 0.126  val_loss_mask: 0.1415  val_loss_rpn_cls: 0.00131  val_loss_rpn_loc: 0.003998  time: 0.1716  data_time: 0.0147  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:21:58 d2.utils.events]: \u001b[0m eta: 0:08:28  iter: 1439  total_loss: 0.4598  loss_cls: 0.1342  loss_box_reg: 0.1381  loss_mask: 0.1482  loss_rpn_cls: 0.0002075  loss_rpn_loc: 0.004285  total_val_loss: 0.3916  val_loss_cls: 0.154  val_loss_box_reg: 0.1227  val_loss_mask: 0.1289  val_loss_rpn_cls: 0.0003114  val_loss_rpn_loc: 0.004037  time: 0.1715  data_time: 0.0082  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:22:03 d2.utils.events]: \u001b[0m eta: 0:08:25  iter: 1459  total_loss: 0.4409  loss_cls: 0.142  loss_box_reg: 0.1419  loss_mask: 0.1528  loss_rpn_cls: 0.0002787  loss_rpn_loc: 0.004988  total_val_loss: 0.4245  val_loss_cls: 0.1326  val_loss_box_reg: 0.1424  val_loss_mask: 0.1359  val_loss_rpn_cls: 0.0004988  val_loss_rpn_loc: 0.003778  time: 0.1718  data_time: 0.0271  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:22:09 d2.utils.events]: \u001b[0m eta: 0:08:22  iter: 1479  total_loss: 0.3406  loss_cls: 0.1178  loss_box_reg: 0.1084  loss_mask: 0.1242  loss_rpn_cls: 0.000366  loss_rpn_loc: 0.004552  total_val_loss: 0.4048  val_loss_cls: 0.1146  val_loss_box_reg: 0.1216  val_loss_mask: 0.1277  val_loss_rpn_cls: 0.001919  val_loss_rpn_loc: 0.005135  time: 0.1719  data_time: 0.0149  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:22:14 d2.utils.events]: \u001b[0m eta: 0:08:20  iter: 1499  total_loss: 0.4236  loss_cls: 0.1121  loss_box_reg: 0.1409  loss_mask: 0.1493  loss_rpn_cls: 0.0007022  loss_rpn_loc: 0.004832  total_val_loss: 0.3402  val_loss_cls: 0.1147  val_loss_box_reg: 0.1204  val_loss_mask: 0.126  val_loss_rpn_cls: 0.0005811  val_loss_rpn_loc: 0.003459  time: 0.1718  data_time: 0.0122  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:22:20 d2.utils.events]: \u001b[0m eta: 0:08:16  iter: 1519  total_loss: 0.3399  loss_cls: 0.1033  loss_box_reg: 0.1148  loss_mask: 0.1317  loss_rpn_cls: 0.0004354  loss_rpn_loc: 0.004152  total_val_loss: 0.4929  val_loss_cls: 0.1406  val_loss_box_reg: 0.1679  val_loss_mask: 0.1647  val_loss_rpn_cls: 0.0005323  val_loss_rpn_loc: 0.004818  time: 0.1720  data_time: 0.0191  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:22:25 d2.utils.events]: \u001b[0m eta: 0:08:13  iter: 1539  total_loss: 0.3162  loss_cls: 0.0936  loss_box_reg: 0.1073  loss_mask: 0.1106  loss_rpn_cls: 0.0005308  loss_rpn_loc: 0.003962  total_val_loss: 0.3317  val_loss_cls: 0.11  val_loss_box_reg: 0.117  val_loss_mask: 0.1209  val_loss_rpn_cls: 0.0002818  val_loss_rpn_loc: 0.004459  time: 0.1720  data_time: 0.0202  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:22:30 d2.utils.events]: \u001b[0m eta: 0:08:09  iter: 1559  total_loss: 0.3636  loss_cls: 0.1037  loss_box_reg: 0.1195  loss_mask: 0.111  loss_rpn_cls: 0.0001271  loss_rpn_loc: 0.00391  total_val_loss: 0.3446  val_loss_cls: 0.1061  val_loss_box_reg: 0.1189  val_loss_mask: 0.1166  val_loss_rpn_cls: 0.0002817  val_loss_rpn_loc: 0.003981  time: 0.1720  data_time: 0.0124  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:22:36 d2.utils.events]: \u001b[0m eta: 0:08:05  iter: 1579  total_loss: 0.3659  loss_cls: 0.1084  loss_box_reg: 0.112  loss_mask: 0.1201  loss_rpn_cls: 0.0002361  loss_rpn_loc: 0.005378  total_val_loss: 0.412  val_loss_cls: 0.1061  val_loss_box_reg: 0.133  val_loss_mask: 0.1573  val_loss_rpn_cls: 0.0002359  val_loss_rpn_loc: 0.003497  time: 0.1720  data_time: 0.0150  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:22:41 d2.utils.events]: \u001b[0m eta: 0:08:01  iter: 1599  total_loss: 0.3132  loss_cls: 0.1146  loss_box_reg: 0.0927  loss_mask: 0.1102  loss_rpn_cls: 0.0006467  loss_rpn_loc: 0.005219  total_val_loss: 0.4771  val_loss_cls: 0.1657  val_loss_box_reg: 0.1621  val_loss_mask: 0.1516  val_loss_rpn_cls: 0.002072  val_loss_rpn_loc: 0.005967  time: 0.1720  data_time: 0.0105  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:22:46 d2.utils.events]: \u001b[0m eta: 0:07:58  iter: 1619  total_loss: 0.3834  loss_cls: 0.09818  loss_box_reg: 0.1266  loss_mask: 0.127  loss_rpn_cls: 0.0005163  loss_rpn_loc: 0.005032  total_val_loss: 0.3164  val_loss_cls: 0.1071  val_loss_box_reg: 0.09834  val_loss_mask: 0.1024  val_loss_rpn_cls: 0.0006266  val_loss_rpn_loc: 0.003975  time: 0.1720  data_time: 0.0081  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:22:52 d2.utils.events]: \u001b[0m eta: 0:07:55  iter: 1639  total_loss: 0.3189  loss_cls: 0.1073  loss_box_reg: 0.09795  loss_mask: 0.1155  loss_rpn_cls: 0.0002197  loss_rpn_loc: 0.0031  total_val_loss: 0.3872  val_loss_cls: 0.1447  val_loss_box_reg: 0.1395  val_loss_mask: 0.1483  val_loss_rpn_cls: 0.0001118  val_loss_rpn_loc: 0.003711  time: 0.1720  data_time: 0.0144  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:22:57 d2.utils.events]: \u001b[0m eta: 0:07:52  iter: 1659  total_loss: 0.32  loss_cls: 0.09833  loss_box_reg: 0.1024  loss_mask: 0.1313  loss_rpn_cls: 0.0006571  loss_rpn_loc: 0.004278  total_val_loss: 0.4642  val_loss_cls: 0.1208  val_loss_box_reg: 0.1533  val_loss_mask: 0.1358  val_loss_rpn_cls: 0.0007712  val_loss_rpn_loc: 0.00398  time: 0.1720  data_time: 0.0142  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:23:02 d2.utils.events]: \u001b[0m eta: 0:07:48  iter: 1679  total_loss: 0.3373  loss_cls: 0.08571  loss_box_reg: 0.1076  loss_mask: 0.114  loss_rpn_cls: 0.0001202  loss_rpn_loc: 0.003668  total_val_loss: 0.3845  val_loss_cls: 0.1159  val_loss_box_reg: 0.1147  val_loss_mask: 0.112  val_loss_rpn_cls: 0.0002112  val_loss_rpn_loc: 0.004023  time: 0.1719  data_time: 0.0132  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:23:07 d2.utils.events]: \u001b[0m eta: 0:07:45  iter: 1699  total_loss: 0.3326  loss_cls: 0.101  loss_box_reg: 0.1139  loss_mask: 0.1139  loss_rpn_cls: 0.0004105  loss_rpn_loc: 0.004374  total_val_loss: 0.4135  val_loss_cls: 0.125  val_loss_box_reg: 0.1311  val_loss_mask: 0.1626  val_loss_rpn_cls: 0.0001535  val_loss_rpn_loc: 0.00436  time: 0.1719  data_time: 0.0128  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:23:13 d2.utils.events]: \u001b[0m eta: 0:07:40  iter: 1719  total_loss: 0.4123  loss_cls: 0.1435  loss_box_reg: 0.1376  loss_mask: 0.114  loss_rpn_cls: 0.0003378  loss_rpn_loc: 0.003785  total_val_loss: 0.3831  val_loss_cls: 0.1201  val_loss_box_reg: 0.1179  val_loss_mask: 0.1153  val_loss_rpn_cls: 0.001359  val_loss_rpn_loc: 0.003996  time: 0.1720  data_time: 0.0133  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:23:18 d2.utils.events]: \u001b[0m eta: 0:07:37  iter: 1739  total_loss: 0.3152  loss_cls: 0.08623  loss_box_reg: 0.103  loss_mask: 0.1032  loss_rpn_cls: 0.0003912  loss_rpn_loc: 0.003475  total_val_loss: 0.3839  val_loss_cls: 0.09946  val_loss_box_reg: 0.08641  val_loss_mask: 0.1399  val_loss_rpn_cls: 0.0003762  val_loss_rpn_loc: 0.003508  time: 0.1719  data_time: 0.0087  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:23:23 d2.utils.events]: \u001b[0m eta: 0:07:33  iter: 1759  total_loss: 0.3598  loss_cls: 0.1078  loss_box_reg: 0.1098  loss_mask: 0.1247  loss_rpn_cls: 0.0004019  loss_rpn_loc: 0.004458  total_val_loss: 0.3468  val_loss_cls: 0.09761  val_loss_box_reg: 0.1085  val_loss_mask: 0.1305  val_loss_rpn_cls: 0.001046  val_loss_rpn_loc: 0.004545  time: 0.1717  data_time: 0.0086  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:23:29 d2.utils.events]: \u001b[0m eta: 0:07:30  iter: 1779  total_loss: 0.3736  loss_cls: 0.1115  loss_box_reg: 0.1186  loss_mask: 0.1246  loss_rpn_cls: 0.0002089  loss_rpn_loc: 0.004655  total_val_loss: 0.4466  val_loss_cls: 0.1368  val_loss_box_reg: 0.152  val_loss_mask: 0.1312  val_loss_rpn_cls: 0.0001518  val_loss_rpn_loc: 0.004864  time: 0.1718  data_time: 0.0148  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:23:34 d2.utils.events]: \u001b[0m eta: 0:07:27  iter: 1799  total_loss: 0.3938  loss_cls: 0.1179  loss_box_reg: 0.1162  loss_mask: 0.1317  loss_rpn_cls: 0.0001515  loss_rpn_loc: 0.004062  total_val_loss: 0.3545  val_loss_cls: 0.1509  val_loss_box_reg: 0.1056  val_loss_mask: 0.114  val_loss_rpn_cls: 0.001542  val_loss_rpn_loc: 0.004676  time: 0.1719  data_time: 0.0207  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:23:40 d2.utils.events]: \u001b[0m eta: 0:07:23  iter: 1819  total_loss: 0.3299  loss_cls: 0.09866  loss_box_reg: 0.09172  loss_mask: 0.1187  loss_rpn_cls: 0.000138  loss_rpn_loc: 0.003528  total_val_loss: 0.4069  val_loss_cls: 0.1075  val_loss_box_reg: 0.1078  val_loss_mask: 0.1612  val_loss_rpn_cls: 0.0001482  val_loss_rpn_loc: 0.003778  time: 0.1719  data_time: 0.0110  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:23:46 d2.utils.events]: \u001b[0m eta: 0:07:21  iter: 1839  total_loss: 0.3474  loss_cls: 0.09641  loss_box_reg: 0.1118  loss_mask: 0.1119  loss_rpn_cls: 0.0007091  loss_rpn_loc: 0.004876  total_val_loss: 0.3385  val_loss_cls: 0.1054  val_loss_box_reg: 0.09739  val_loss_mask: 0.131  val_loss_rpn_cls: 0.0001285  val_loss_rpn_loc: 0.004402  time: 0.1720  data_time: 0.0135  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:23:51 d2.utils.events]: \u001b[0m eta: 0:07:19  iter: 1859  total_loss: 0.3115  loss_cls: 0.08791  loss_box_reg: 0.1076  loss_mask: 0.115  loss_rpn_cls: 0.0003413  loss_rpn_loc: 0.005415  total_val_loss: 0.4106  val_loss_cls: 0.1564  val_loss_box_reg: 0.1573  val_loss_mask: 0.1468  val_loss_rpn_cls: 0.002852  val_loss_rpn_loc: 0.004618  time: 0.1720  data_time: 0.0153  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:23:56 d2.utils.events]: \u001b[0m eta: 0:07:16  iter: 1879  total_loss: 0.3105  loss_cls: 0.08117  loss_box_reg: 0.1157  loss_mask: 0.1044  loss_rpn_cls: 0.0007126  loss_rpn_loc: 0.004576  total_val_loss: 0.3713  val_loss_cls: 0.108  val_loss_box_reg: 0.1308  val_loss_mask: 0.138  val_loss_rpn_cls: 9.613e-05  val_loss_rpn_loc: 0.003259  time: 0.1720  data_time: 0.0087  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:24:02 d2.utils.events]: \u001b[0m eta: 0:07:13  iter: 1899  total_loss: 0.2716  loss_cls: 0.08168  loss_box_reg: 0.08671  loss_mask: 0.1079  loss_rpn_cls: 0.0002171  loss_rpn_loc: 0.003807  total_val_loss: 0.4994  val_loss_cls: 0.1593  val_loss_box_reg: 0.1348  val_loss_mask: 0.1776  val_loss_rpn_cls: 0.0008877  val_loss_rpn_loc: 0.004216  time: 0.1719  data_time: 0.0156  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:24:07 d2.utils.events]: \u001b[0m eta: 0:07:10  iter: 1919  total_loss: 0.4026  loss_cls: 0.1168  loss_box_reg: 0.1366  loss_mask: 0.1144  loss_rpn_cls: 0.001206  loss_rpn_loc: 0.004825  total_val_loss: 0.3219  val_loss_cls: 0.09407  val_loss_box_reg: 0.1052  val_loss_mask: 0.1071  val_loss_rpn_cls: 0.0009938  val_loss_rpn_loc: 0.004624  time: 0.1718  data_time: 0.0064  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:24:12 d2.utils.events]: \u001b[0m eta: 0:07:09  iter: 1939  total_loss: 0.3518  loss_cls: 0.08045  loss_box_reg: 0.1139  loss_mask: 0.1155  loss_rpn_cls: 0.0001191  loss_rpn_loc: 0.003709  total_val_loss: 0.3662  val_loss_cls: 0.0947  val_loss_box_reg: 0.1145  val_loss_mask: 0.1438  val_loss_rpn_cls: 0.000626  val_loss_rpn_loc: 0.004345  time: 0.1719  data_time: 0.0194  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:24:18 d2.utils.events]: \u001b[0m eta: 0:07:05  iter: 1959  total_loss: 0.2936  loss_cls: 0.099  loss_box_reg: 0.09877  loss_mask: 0.09622  loss_rpn_cls: 0.0003247  loss_rpn_loc: 0.003395  total_val_loss: 0.3334  val_loss_cls: 0.09202  val_loss_box_reg: 0.1039  val_loss_mask: 0.1266  val_loss_rpn_cls: 0.0002363  val_loss_rpn_loc: 0.003593  time: 0.1718  data_time: 0.0072  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:24:23 d2.utils.events]: \u001b[0m eta: 0:07:00  iter: 1979  total_loss: 0.3174  loss_cls: 0.103  loss_box_reg: 0.09738  loss_mask: 0.1058  loss_rpn_cls: 7.552e-05  loss_rpn_loc: 0.004085  total_val_loss: 0.3451  val_loss_cls: 0.1127  val_loss_box_reg: 0.1337  val_loss_mask: 0.1184  val_loss_rpn_cls: 0.00176  val_loss_rpn_loc: 0.004748  time: 0.1717  data_time: 0.0075  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:24:28 d2.utils.events]: \u001b[0m eta: 0:06:57  iter: 1999  total_loss: 0.3252  loss_cls: 0.08251  loss_box_reg: 0.1029  loss_mask: 0.1266  loss_rpn_cls: 0.0004178  loss_rpn_loc: 0.003984  total_val_loss: 0.3796  val_loss_cls: 0.09328  val_loss_box_reg: 0.1192  val_loss_mask: 0.1623  val_loss_rpn_cls: 0.0004311  val_loss_rpn_loc: 0.004111  time: 0.1717  data_time: 0.0150  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:24:34 d2.utils.events]: \u001b[0m eta: 0:06:54  iter: 2019  total_loss: 0.358  loss_cls: 0.1119  loss_box_reg: 0.113  loss_mask: 0.122  loss_rpn_cls: 7.542e-05  loss_rpn_loc: 0.003887  total_val_loss: 0.3536  val_loss_cls: 0.09497  val_loss_box_reg: 0.107  val_loss_mask: 0.118  val_loss_rpn_cls: 0.0005434  val_loss_rpn_loc: 0.004179  time: 0.1716  data_time: 0.0083  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:24:39 d2.utils.events]: \u001b[0m eta: 0:06:49  iter: 2039  total_loss: 0.2743  loss_cls: 0.09015  loss_box_reg: 0.07343  loss_mask: 0.1025  loss_rpn_cls: 0.0002798  loss_rpn_loc: 0.003164  total_val_loss: 0.3312  val_loss_cls: 0.1038  val_loss_box_reg: 0.1051  val_loss_mask: 0.1322  val_loss_rpn_cls: 0.0002635  val_loss_rpn_loc: 0.003173  time: 0.1715  data_time: 0.0088  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:24:44 d2.utils.events]: \u001b[0m eta: 0:06:46  iter: 2059  total_loss: 0.38  loss_cls: 0.0957  loss_box_reg: 0.1063  loss_mask: 0.1105  loss_rpn_cls: 0.0002442  loss_rpn_loc: 0.004001  total_val_loss: 0.4352  val_loss_cls: 0.1158  val_loss_box_reg: 0.1421  val_loss_mask: 0.1532  val_loss_rpn_cls: 0.0007701  val_loss_rpn_loc: 0.003555  time: 0.1715  data_time: 0.0067  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:24:50 d2.utils.events]: \u001b[0m eta: 0:06:43  iter: 2079  total_loss: 0.3484  loss_cls: 0.07969  loss_box_reg: 0.1239  loss_mask: 0.1063  loss_rpn_cls: 0.0002491  loss_rpn_loc: 0.004023  total_val_loss: 0.4012  val_loss_cls: 0.1218  val_loss_box_reg: 0.1189  val_loss_mask: 0.1483  val_loss_rpn_cls: 0.0001305  val_loss_rpn_loc: 0.005292  time: 0.1717  data_time: 0.0273  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:24:55 d2.utils.events]: \u001b[0m eta: 0:06:39  iter: 2099  total_loss: 0.2905  loss_cls: 0.07548  loss_box_reg: 0.0834  loss_mask: 0.1247  loss_rpn_cls: 0.0001583  loss_rpn_loc: 0.00345  total_val_loss: 0.4326  val_loss_cls: 0.09841  val_loss_box_reg: 0.1308  val_loss_mask: 0.1539  val_loss_rpn_cls: 0.001058  val_loss_rpn_loc: 0.003672  time: 0.1716  data_time: 0.0116  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:25:00 d2.utils.events]: \u001b[0m eta: 0:06:36  iter: 2119  total_loss: 0.3064  loss_cls: 0.08921  loss_box_reg: 0.1051  loss_mask: 0.08921  loss_rpn_cls: 0.0003257  loss_rpn_loc: 0.003988  total_val_loss: 0.3823  val_loss_cls: 0.1292  val_loss_box_reg: 0.1247  val_loss_mask: 0.1378  val_loss_rpn_cls: 0.0005273  val_loss_rpn_loc: 0.004835  time: 0.1716  data_time: 0.0150  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:25:06 d2.utils.events]: \u001b[0m eta: 0:06:32  iter: 2139  total_loss: 0.2827  loss_cls: 0.08938  loss_box_reg: 0.08807  loss_mask: 0.0849  loss_rpn_cls: 0.0004842  loss_rpn_loc: 0.003415  total_val_loss: 0.3371  val_loss_cls: 0.09537  val_loss_box_reg: 0.09937  val_loss_mask: 0.109  val_loss_rpn_cls: 0.001013  val_loss_rpn_loc: 0.004424  time: 0.1716  data_time: 0.0158  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:25:11 d2.utils.events]: \u001b[0m eta: 0:06:29  iter: 2159  total_loss: 0.3632  loss_cls: 0.1026  loss_box_reg: 0.1175  loss_mask: 0.1055  loss_rpn_cls: 0.0007982  loss_rpn_loc: 0.005931  total_val_loss: 0.3152  val_loss_cls: 0.09982  val_loss_box_reg: 0.08611  val_loss_mask: 0.114  val_loss_rpn_cls: 3.196e-05  val_loss_rpn_loc: 0.003393  time: 0.1717  data_time: 0.0112  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:25:17 d2.utils.events]: \u001b[0m eta: 0:06:25  iter: 2179  total_loss: 0.3253  loss_cls: 0.08901  loss_box_reg: 0.1053  loss_mask: 0.1034  loss_rpn_cls: 0.0002301  loss_rpn_loc: 0.003388  total_val_loss: 0.4782  val_loss_cls: 0.1578  val_loss_box_reg: 0.1172  val_loss_mask: 0.1502  val_loss_rpn_cls: 0.0004073  val_loss_rpn_loc: 0.003499  time: 0.1716  data_time: 0.0091  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:25:22 d2.utils.events]: \u001b[0m eta: 0:06:22  iter: 2199  total_loss: 0.3759  loss_cls: 0.1081  loss_box_reg: 0.1259  loss_mask: 0.1282  loss_rpn_cls: 0.0004372  loss_rpn_loc: 0.005653  total_val_loss: 0.3106  val_loss_cls: 0.1008  val_loss_box_reg: 0.09425  val_loss_mask: 0.1086  val_loss_rpn_cls: 0.0001831  val_loss_rpn_loc: 0.00361  time: 0.1716  data_time: 0.0123  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:25:27 d2.utils.events]: \u001b[0m eta: 0:06:18  iter: 2219  total_loss: 0.2876  loss_cls: 0.08336  loss_box_reg: 0.0941  loss_mask: 0.1002  loss_rpn_cls: 0.0003779  loss_rpn_loc: 0.004061  total_val_loss: 0.4151  val_loss_cls: 0.07836  val_loss_box_reg: 0.1056  val_loss_mask: 0.1656  val_loss_rpn_cls: 0.0002527  val_loss_rpn_loc: 0.003849  time: 0.1717  data_time: 0.0166  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:25:33 d2.utils.events]: \u001b[0m eta: 0:06:15  iter: 2239  total_loss: 0.3184  loss_cls: 0.0924  loss_box_reg: 0.09256  loss_mask: 0.1088  loss_rpn_cls: 0.000598  loss_rpn_loc: 0.00387  total_val_loss: 0.3628  val_loss_cls: 0.09605  val_loss_box_reg: 0.1114  val_loss_mask: 0.106  val_loss_rpn_cls: 0.0003572  val_loss_rpn_loc: 0.003157  time: 0.1717  data_time: 0.0203  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:25:38 d2.utils.events]: \u001b[0m eta: 0:06:11  iter: 2259  total_loss: 0.2814  loss_cls: 0.0768  loss_box_reg: 0.08304  loss_mask: 0.09574  loss_rpn_cls: 0.0001774  loss_rpn_loc: 0.003292  total_val_loss: 0.3033  val_loss_cls: 0.121  val_loss_box_reg: 0.1125  val_loss_mask: 0.1322  val_loss_rpn_cls: 0.0001492  val_loss_rpn_loc: 0.003467  time: 0.1717  data_time: 0.0149  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:25:43 d2.utils.events]: \u001b[0m eta: 0:06:08  iter: 2279  total_loss: 0.3163  loss_cls: 0.07523  loss_box_reg: 0.1067  loss_mask: 0.09802  loss_rpn_cls: 0.001085  loss_rpn_loc: 0.004263  total_val_loss: 0.4803  val_loss_cls: 0.1929  val_loss_box_reg: 0.1449  val_loss_mask: 0.1447  val_loss_rpn_cls: 0.0008909  val_loss_rpn_loc: 0.003879  time: 0.1716  data_time: 0.0105  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:25:48 d2.utils.events]: \u001b[0m eta: 0:06:04  iter: 2299  total_loss: 0.2769  loss_cls: 0.08155  loss_box_reg: 0.1031  loss_mask: 0.08702  loss_rpn_cls: 0.0003325  loss_rpn_loc: 0.004918  total_val_loss: 0.3352  val_loss_cls: 0.08149  val_loss_box_reg: 0.06907  val_loss_mask: 0.1304  val_loss_rpn_cls: 0.0002527  val_loss_rpn_loc: 0.003636  time: 0.1715  data_time: 0.0087  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:25:54 d2.utils.events]: \u001b[0m eta: 0:06:01  iter: 2319  total_loss: 0.2894  loss_cls: 0.07926  loss_box_reg: 0.08135  loss_mask: 0.09277  loss_rpn_cls: 0.0001774  loss_rpn_loc: 0.003158  total_val_loss: 0.283  val_loss_cls: 0.1054  val_loss_box_reg: 0.08631  val_loss_mask: 0.1065  val_loss_rpn_cls: 0.0005556  val_loss_rpn_loc: 0.003705  time: 0.1716  data_time: 0.0220  lr: 0.00025  max_mem: 2180M\n",
            "\u001b[32m[06/14 03:25:59 d2.utils.events]: \u001b[0m eta: 0:05:58  iter: 2339  total_loss: 0.2971  loss_cls: 0.08355  loss_box_reg: 0.09497  loss_mask: 0.1077  loss_rpn_cls: 0.0002231  loss_rpn_loc: 0.003514  total_val_loss: 0.3259  val_loss_cls: 0.07977  val_loss_box_reg: 0.08259  val_loss_mask: 0.1239  val_loss_rpn_cls: 0.0003999  val_loss_rpn_loc: 0.003139  time: 0.1716  data_time: 0.0079  lr: 0.00025  max_mem: 2192M\n",
            "\u001b[32m[06/14 03:26:05 d2.utils.events]: \u001b[0m eta: 0:05:54  iter: 2359  total_loss: 0.2853  loss_cls: 0.061  loss_box_reg: 0.08943  loss_mask: 0.1092  loss_rpn_cls: 0.0001597  loss_rpn_loc: 0.004072  total_val_loss: 0.4423  val_loss_cls: 0.1712  val_loss_box_reg: 0.1564  val_loss_mask: 0.1623  val_loss_rpn_cls: 0.000945  val_loss_rpn_loc: 0.004639  time: 0.1716  data_time: 0.0090  lr: 0.00025  max_mem: 2192M\n",
            "\u001b[32m[06/14 03:26:10 d2.utils.events]: \u001b[0m eta: 0:05:50  iter: 2379  total_loss: 0.2477  loss_cls: 0.06036  loss_box_reg: 0.08784  loss_mask: 0.08997  loss_rpn_cls: 0.0001577  loss_rpn_loc: 0.00333  total_val_loss: 0.2895  val_loss_cls: 0.0864  val_loss_box_reg: 0.1036  val_loss_mask: 0.1225  val_loss_rpn_cls: 0.000283  val_loss_rpn_loc: 0.003448  time: 0.1714  data_time: 0.0059  lr: 0.00025  max_mem: 2192M\n",
            "\u001b[32m[06/14 03:26:15 d2.utils.events]: \u001b[0m eta: 0:05:47  iter: 2399  total_loss: 0.3243  loss_cls: 0.09715  loss_box_reg: 0.09869  loss_mask: 0.1018  loss_rpn_cls: 0.0001544  loss_rpn_loc: 0.003778  total_val_loss: 0.3803  val_loss_cls: 0.09478  val_loss_box_reg: 0.09742  val_loss_mask: 0.1279  val_loss_rpn_cls: 0.0003566  val_loss_rpn_loc: 0.003959  time: 0.1715  data_time: 0.0162  lr: 0.00025  max_mem: 2192M\n",
            "\u001b[32m[06/14 03:26:20 d2.utils.events]: \u001b[0m eta: 0:05:43  iter: 2419  total_loss: 0.2682  loss_cls: 0.05636  loss_box_reg: 0.1016  loss_mask: 0.1159  loss_rpn_cls: 0.0001128  loss_rpn_loc: 0.004504  total_val_loss: 0.3414  val_loss_cls: 0.08902  val_loss_box_reg: 0.09167  val_loss_mask: 0.1398  val_loss_rpn_cls: 0.00025  val_loss_rpn_loc: 0.003571  time: 0.1715  data_time: 0.0138  lr: 0.00025  max_mem: 2192M\n",
            "\u001b[32m[06/14 03:26:26 d2.utils.events]: \u001b[0m eta: 0:05:40  iter: 2439  total_loss: 0.2845  loss_cls: 0.08351  loss_box_reg: 0.09448  loss_mask: 0.104  loss_rpn_cls: 0.0001734  loss_rpn_loc: 0.004346  total_val_loss: 0.3536  val_loss_cls: 0.1405  val_loss_box_reg: 0.1137  val_loss_mask: 0.1057  val_loss_rpn_cls: 0.0003955  val_loss_rpn_loc: 0.003713  time: 0.1715  data_time: 0.0180  lr: 0.00025  max_mem: 2192M\n",
            "\u001b[32m[06/14 03:26:32 d2.utils.events]: \u001b[0m eta: 0:05:37  iter: 2459  total_loss: 0.3327  loss_cls: 0.07906  loss_box_reg: 0.1148  loss_mask: 0.1042  loss_rpn_cls: 0.000321  loss_rpn_loc: 0.003673  total_val_loss: 0.3947  val_loss_cls: 0.07872  val_loss_box_reg: 0.09565  val_loss_mask: 0.1406  val_loss_rpn_cls: 0.0001717  val_loss_rpn_loc: 0.00281  time: 0.1717  data_time: 0.0228  lr: 0.00025  max_mem: 2192M\n",
            "\u001b[32m[06/14 03:26:37 d2.utils.events]: \u001b[0m eta: 0:05:33  iter: 2479  total_loss: 0.2677  loss_cls: 0.08372  loss_box_reg: 0.08851  loss_mask: 0.1026  loss_rpn_cls: 7.922e-05  loss_rpn_loc: 0.004606  total_val_loss: 0.3165  val_loss_cls: 0.09339  val_loss_box_reg: 0.1034  val_loss_mask: 0.126  val_loss_rpn_cls: 0.0008825  val_loss_rpn_loc: 0.004158  time: 0.1717  data_time: 0.0140  lr: 0.00025  max_mem: 2192M\n",
            "\u001b[32m[06/14 03:26:42 d2.utils.events]: \u001b[0m eta: 0:05:29  iter: 2499  total_loss: 0.2503  loss_cls: 0.06597  loss_box_reg: 0.09396  loss_mask: 0.07633  loss_rpn_cls: 0.0003631  loss_rpn_loc: 0.003496  total_val_loss: 0.3182  val_loss_cls: 0.1053  val_loss_box_reg: 0.1066  val_loss_mask: 0.1086  val_loss_rpn_cls: 0.0004476  val_loss_rpn_loc: 0.004027  time: 0.1716  data_time: 0.0134  lr: 0.00025  max_mem: 2192M\n",
            "\u001b[32m[06/14 03:26:48 d2.utils.events]: \u001b[0m eta: 0:05:26  iter: 2519  total_loss: 0.2898  loss_cls: 0.0687  loss_box_reg: 0.08853  loss_mask: 0.09982  loss_rpn_cls: 0.0008732  loss_rpn_loc: 0.003594  total_val_loss: 0.5152  val_loss_cls: 0.1664  val_loss_box_reg: 0.1238  val_loss_mask: 0.154  val_loss_rpn_cls: 0.001357  val_loss_rpn_loc: 0.005169  time: 0.1717  data_time: 0.0157  lr: 0.00025  max_mem: 2192M\n",
            "\u001b[32m[06/14 03:26:53 d2.utils.events]: \u001b[0m eta: 0:05:23  iter: 2539  total_loss: 0.2522  loss_cls: 0.06637  loss_box_reg: 0.07911  loss_mask: 0.0877  loss_rpn_cls: 0.0001698  loss_rpn_loc: 0.003927  total_val_loss: 0.2858  val_loss_cls: 0.08962  val_loss_box_reg: 0.09852  val_loss_mask: 0.09786  val_loss_rpn_cls: 0.000176  val_loss_rpn_loc: 0.004232  time: 0.1717  data_time: 0.0139  lr: 0.00025  max_mem: 2192M\n",
            "\u001b[32m[06/14 03:26:58 d2.utils.events]: \u001b[0m eta: 0:05:20  iter: 2559  total_loss: 0.2132  loss_cls: 0.05599  loss_box_reg: 0.06597  loss_mask: 0.08354  loss_rpn_cls: 7.898e-05  loss_rpn_loc: 0.00358  total_val_loss: 0.3519  val_loss_cls: 0.09084  val_loss_box_reg: 0.1272  val_loss_mask: 0.124  val_loss_rpn_cls: 0.0007126  val_loss_rpn_loc: 0.003916  time: 0.1717  data_time: 0.0137  lr: 0.00025  max_mem: 2192M\n",
            "\u001b[32m[06/14 03:27:04 d2.utils.events]: \u001b[0m eta: 0:05:17  iter: 2579  total_loss: 0.2854  loss_cls: 0.07471  loss_box_reg: 0.1145  loss_mask: 0.09552  loss_rpn_cls: 0.0001187  loss_rpn_loc: 0.005033  total_val_loss: 0.2958  val_loss_cls: 0.09312  val_loss_box_reg: 0.09219  val_loss_mask: 0.1075  val_loss_rpn_cls: 0.0001677  val_loss_rpn_loc: 0.003209  time: 0.1718  data_time: 0.0237  lr: 0.00025  max_mem: 2192M\n",
            "\u001b[32m[06/14 03:27:09 d2.utils.events]: \u001b[0m eta: 0:05:14  iter: 2599  total_loss: 0.2787  loss_cls: 0.06954  loss_box_reg: 0.09777  loss_mask: 0.09796  loss_rpn_cls: 0.0001893  loss_rpn_loc: 0.004401  total_val_loss: 0.3239  val_loss_cls: 0.1106  val_loss_box_reg: 0.09862  val_loss_mask: 0.11  val_loss_rpn_cls: 0.0002045  val_loss_rpn_loc: 0.003875  time: 0.1718  data_time: 0.0104  lr: 0.00025  max_mem: 2192M\n",
            "\u001b[32m[06/14 03:27:14 d2.utils.events]: \u001b[0m eta: 0:05:11  iter: 2619  total_loss: 0.2707  loss_cls: 0.07115  loss_box_reg: 0.07951  loss_mask: 0.09604  loss_rpn_cls: 0.0003253  loss_rpn_loc: 0.00446  total_val_loss: 0.39  val_loss_cls: 0.1052  val_loss_box_reg: 0.1055  val_loss_mask: 0.1434  val_loss_rpn_cls: 0.0001542  val_loss_rpn_loc: 0.004889  time: 0.1718  data_time: 0.0123  lr: 0.00025  max_mem: 2192M\n",
            "\u001b[32m[06/14 03:27:20 d2.utils.events]: \u001b[0m eta: 0:05:07  iter: 2639  total_loss: 0.3204  loss_cls: 0.08258  loss_box_reg: 0.1181  loss_mask: 0.105  loss_rpn_cls: 0.0002005  loss_rpn_loc: 0.00388  total_val_loss: 0.335  val_loss_cls: 0.1181  val_loss_box_reg: 0.1039  val_loss_mask: 0.107  val_loss_rpn_cls: 9.622e-05  val_loss_rpn_loc: 0.003737  time: 0.1719  data_time: 0.0169  lr: 0.00025  max_mem: 2192M\n",
            "\u001b[32m[06/14 03:27:25 d2.utils.events]: \u001b[0m eta: 0:05:04  iter: 2659  total_loss: 0.238  loss_cls: 0.07039  loss_box_reg: 0.07508  loss_mask: 0.0905  loss_rpn_cls: 8.599e-05  loss_rpn_loc: 0.003675  total_val_loss: 0.3869  val_loss_cls: 0.09812  val_loss_box_reg: 0.109  val_loss_mask: 0.1508  val_loss_rpn_cls: 0.0005392  val_loss_rpn_loc: 0.004988  time: 0.1719  data_time: 0.0180  lr: 0.00025  max_mem: 2192M\n",
            "\u001b[32m[06/14 03:27:30 d2.utils.events]: \u001b[0m eta: 0:05:00  iter: 2679  total_loss: 0.2948  loss_cls: 0.07671  loss_box_reg: 0.09612  loss_mask: 0.0954  loss_rpn_cls: 0.0002515  loss_rpn_loc: 0.003404  total_val_loss: 0.3703  val_loss_cls: 0.1134  val_loss_box_reg: 0.09685  val_loss_mask: 0.1299  val_loss_rpn_cls: 0.0004467  val_loss_rpn_loc: 0.003305  time: 0.1718  data_time: 0.0101  lr: 0.00025  max_mem: 2192M\n",
            "\u001b[32m[06/14 03:27:36 d2.utils.events]: \u001b[0m eta: 0:04:56  iter: 2699  total_loss: 0.2342  loss_cls: 0.06  loss_box_reg: 0.07987  loss_mask: 0.09455  loss_rpn_cls: 0.0001073  loss_rpn_loc: 0.003558  total_val_loss: 0.2744  val_loss_cls: 0.08424  val_loss_box_reg: 0.09251  val_loss_mask: 0.0937  val_loss_rpn_cls: 0.000193  val_loss_rpn_loc: 0.003365  time: 0.1719  data_time: 0.0162  lr: 0.00025  max_mem: 2192M\n",
            "\u001b[32m[06/14 03:27:41 d2.utils.events]: \u001b[0m eta: 0:04:53  iter: 2719  total_loss: 0.2182  loss_cls: 0.05568  loss_box_reg: 0.07227  loss_mask: 0.08126  loss_rpn_cls: 0.0002373  loss_rpn_loc: 0.002809  total_val_loss: 0.4195  val_loss_cls: 0.1241  val_loss_box_reg: 0.1104  val_loss_mask: 0.1332  val_loss_rpn_cls: 0.0009231  val_loss_rpn_loc: 0.004349  time: 0.1718  data_time: 0.0096  lr: 0.00025  max_mem: 2192M\n",
            "\u001b[32m[06/14 03:27:46 d2.utils.events]: \u001b[0m eta: 0:04:49  iter: 2739  total_loss: 0.259  loss_cls: 0.06992  loss_box_reg: 0.08095  loss_mask: 0.1006  loss_rpn_cls: 0.0001375  loss_rpn_loc: 0.003373  total_val_loss: 0.2996  val_loss_cls: 0.1152  val_loss_box_reg: 0.09826  val_loss_mask: 0.1162  val_loss_rpn_cls: 0.0005878  val_loss_rpn_loc: 0.003613  time: 0.1718  data_time: 0.0065  lr: 0.00025  max_mem: 2192M\n",
            "\u001b[32m[06/14 03:27:52 d2.utils.events]: \u001b[0m eta: 0:04:47  iter: 2759  total_loss: 0.276  loss_cls: 0.05715  loss_box_reg: 0.08982  loss_mask: 0.09943  loss_rpn_cls: 0.000154  loss_rpn_loc: 0.003831  total_val_loss: 0.354  val_loss_cls: 0.1051  val_loss_box_reg: 0.1124  val_loss_mask: 0.1226  val_loss_rpn_cls: 0.0003048  val_loss_rpn_loc: 0.004185  time: 0.1717  data_time: 0.0110  lr: 0.00025  max_mem: 2192M\n",
            "\u001b[32m[06/14 03:27:57 d2.utils.events]: \u001b[0m eta: 0:04:42  iter: 2779  total_loss: 0.2063  loss_cls: 0.07002  loss_box_reg: 0.06286  loss_mask: 0.08808  loss_rpn_cls: 3.364e-05  loss_rpn_loc: 0.002846  total_val_loss: 0.3825  val_loss_cls: 0.1106  val_loss_box_reg: 0.1025  val_loss_mask: 0.1367  val_loss_rpn_cls: 0.0001933  val_loss_rpn_loc: 0.003183  time: 0.1717  data_time: 0.0111  lr: 0.00025  max_mem: 2192M\n",
            "\u001b[32m[06/14 03:28:02 d2.utils.events]: \u001b[0m eta: 0:04:39  iter: 2799  total_loss: 0.2456  loss_cls: 0.06173  loss_box_reg: 0.07644  loss_mask: 0.09062  loss_rpn_cls: 0.0001159  loss_rpn_loc: 0.003837  total_val_loss: 0.3985  val_loss_cls: 0.1086  val_loss_box_reg: 0.1067  val_loss_mask: 0.1512  val_loss_rpn_cls: 0.0001007  val_loss_rpn_loc: 0.004003  time: 0.1717  data_time: 0.0109  lr: 0.00025  max_mem: 2192M\n",
            "\u001b[32m[06/14 03:28:07 d2.utils.events]: \u001b[0m eta: 0:04:35  iter: 2819  total_loss: 0.2623  loss_cls: 0.07559  loss_box_reg: 0.08866  loss_mask: 0.1026  loss_rpn_cls: 0.0001653  loss_rpn_loc: 0.004163  total_val_loss: 0.3962  val_loss_cls: 0.127  val_loss_box_reg: 0.1163  val_loss_mask: 0.1444  val_loss_rpn_cls: 0.0002932  val_loss_rpn_loc: 0.004316  time: 0.1716  data_time: 0.0102  lr: 0.00025  max_mem: 2192M\n",
            "\u001b[32m[06/14 03:28:13 d2.utils.events]: \u001b[0m eta: 0:04:31  iter: 2839  total_loss: 0.2365  loss_cls: 0.07278  loss_box_reg: 0.08427  loss_mask: 0.08345  loss_rpn_cls: 5.316e-05  loss_rpn_loc: 0.003596  total_val_loss: 0.4054  val_loss_cls: 0.1408  val_loss_box_reg: 0.0987  val_loss_mask: 0.1148  val_loss_rpn_cls: 0.0003214  val_loss_rpn_loc: 0.003752  time: 0.1717  data_time: 0.0145  lr: 0.00025  max_mem: 2192M\n",
            "\u001b[32m[06/14 03:28:18 d2.utils.events]: \u001b[0m eta: 0:04:28  iter: 2859  total_loss: 0.2442  loss_cls: 0.07309  loss_box_reg: 0.08154  loss_mask: 0.09675  loss_rpn_cls: 0.0003908  loss_rpn_loc: 0.004079  total_val_loss: 0.2741  val_loss_cls: 0.0619  val_loss_box_reg: 0.09426  val_loss_mask: 0.1112  val_loss_rpn_cls: 0.0001013  val_loss_rpn_loc: 0.003378  time: 0.1716  data_time: 0.0115  lr: 0.00025  max_mem: 2192M\n",
            "\u001b[32m[06/14 03:28:24 d2.utils.events]: \u001b[0m eta: 0:04:25  iter: 2879  total_loss: 0.2657  loss_cls: 0.0716  loss_box_reg: 0.07288  loss_mask: 0.09201  loss_rpn_cls: 9.69e-05  loss_rpn_loc: 0.005025  total_val_loss: 0.4032  val_loss_cls: 0.1167  val_loss_box_reg: 0.138  val_loss_mask: 0.1568  val_loss_rpn_cls: 0.0002823  val_loss_rpn_loc: 0.00428  time: 0.1717  data_time: 0.0171  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:28:29 d2.utils.events]: \u001b[0m eta: 0:04:21  iter: 2899  total_loss: 0.2084  loss_cls: 0.05259  loss_box_reg: 0.06699  loss_mask: 0.08583  loss_rpn_cls: 0.0001181  loss_rpn_loc: 0.002571  total_val_loss: 0.3283  val_loss_cls: 0.07483  val_loss_box_reg: 0.1011  val_loss_mask: 0.1217  val_loss_rpn_cls: 0.0002387  val_loss_rpn_loc: 0.003784  time: 0.1716  data_time: 0.0078  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:28:34 d2.utils.events]: \u001b[0m eta: 0:04:18  iter: 2919  total_loss: 0.243  loss_cls: 0.06549  loss_box_reg: 0.07996  loss_mask: 0.08822  loss_rpn_cls: 8.063e-05  loss_rpn_loc: 0.002903  total_val_loss: 0.3618  val_loss_cls: 0.1416  val_loss_box_reg: 0.1149  val_loss_mask: 0.1359  val_loss_rpn_cls: 0.001178  val_loss_rpn_loc: 0.005292  time: 0.1716  data_time: 0.0144  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:28:39 d2.utils.events]: \u001b[0m eta: 0:04:15  iter: 2939  total_loss: 0.2518  loss_cls: 0.05186  loss_box_reg: 0.08606  loss_mask: 0.08845  loss_rpn_cls: 0.0001416  loss_rpn_loc: 0.003175  total_val_loss: 0.2675  val_loss_cls: 0.06839  val_loss_box_reg: 0.0695  val_loss_mask: 0.09758  val_loss_rpn_cls: 0.0003059  val_loss_rpn_loc: 0.002498  time: 0.1716  data_time: 0.0157  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:28:45 d2.utils.events]: \u001b[0m eta: 0:04:11  iter: 2959  total_loss: 0.2274  loss_cls: 0.05156  loss_box_reg: 0.07415  loss_mask: 0.08542  loss_rpn_cls: 9.622e-05  loss_rpn_loc: 0.003161  total_val_loss: 0.3742  val_loss_cls: 0.119  val_loss_box_reg: 0.1176  val_loss_mask: 0.1276  val_loss_rpn_cls: 0.0002282  val_loss_rpn_loc: 0.003209  time: 0.1716  data_time: 0.0072  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:28:50 d2.utils.events]: \u001b[0m eta: 0:04:08  iter: 2979  total_loss: 0.2542  loss_cls: 0.06004  loss_box_reg: 0.08215  loss_mask: 0.1039  loss_rpn_cls: 0.0002314  loss_rpn_loc: 0.003794  total_val_loss: 0.4365  val_loss_cls: 0.1773  val_loss_box_reg: 0.1118  val_loss_mask: 0.1369  val_loss_rpn_cls: 0.0007398  val_loss_rpn_loc: 0.00465  time: 0.1716  data_time: 0.0167  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:28:56 d2.utils.events]: \u001b[0m eta: 0:04:05  iter: 2999  total_loss: 0.2469  loss_cls: 0.06104  loss_box_reg: 0.08973  loss_mask: 0.08055  loss_rpn_cls: 0.0005168  loss_rpn_loc: 0.004044  total_val_loss: 0.311  val_loss_cls: 0.06704  val_loss_box_reg: 0.07272  val_loss_mask: 0.1336  val_loss_rpn_cls: 0.0004214  val_loss_rpn_loc: 0.003428  time: 0.1717  data_time: 0.0165  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:29:00 d2.utils.events]: \u001b[0m eta: 0:04:01  iter: 3019  total_loss: 0.2213  loss_cls: 0.0527  loss_box_reg: 0.07459  loss_mask: 0.0837  loss_rpn_cls: 0.0002213  loss_rpn_loc: 0.00383  total_val_loss: 0.3736  val_loss_cls: 0.1322  val_loss_box_reg: 0.1026  val_loss_mask: 0.1407  val_loss_rpn_cls: 0.0005568  val_loss_rpn_loc: 0.003621  time: 0.1716  data_time: 0.0102  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:29:06 d2.utils.events]: \u001b[0m eta: 0:03:58  iter: 3039  total_loss: 0.2804  loss_cls: 0.07669  loss_box_reg: 0.0764  loss_mask: 0.09585  loss_rpn_cls: 0.0001207  loss_rpn_loc: 0.003752  total_val_loss: 0.3633  val_loss_cls: 0.1095  val_loss_box_reg: 0.0977  val_loss_mask: 0.1536  val_loss_rpn_cls: 0.0009641  val_loss_rpn_loc: 0.004539  time: 0.1716  data_time: 0.0104  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:29:11 d2.utils.events]: \u001b[0m eta: 0:03:55  iter: 3059  total_loss: 0.2931  loss_cls: 0.06526  loss_box_reg: 0.1022  loss_mask: 0.1001  loss_rpn_cls: 0.0001783  loss_rpn_loc: 0.003857  total_val_loss: 0.4249  val_loss_cls: 0.1234  val_loss_box_reg: 0.1157  val_loss_mask: 0.122  val_loss_rpn_cls: 0.0001018  val_loss_rpn_loc: 0.003524  time: 0.1716  data_time: 0.0168  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:29:16 d2.utils.events]: \u001b[0m eta: 0:03:51  iter: 3079  total_loss: 0.267  loss_cls: 0.07297  loss_box_reg: 0.0804  loss_mask: 0.1098  loss_rpn_cls: 9.574e-05  loss_rpn_loc: 0.00312  total_val_loss: 0.4627  val_loss_cls: 0.1005  val_loss_box_reg: 0.1161  val_loss_mask: 0.1538  val_loss_rpn_cls: 0.0005748  val_loss_rpn_loc: 0.003825  time: 0.1716  data_time: 0.0103  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:29:22 d2.utils.events]: \u001b[0m eta: 0:03:48  iter: 3099  total_loss: 0.2428  loss_cls: 0.05779  loss_box_reg: 0.08956  loss_mask: 0.08169  loss_rpn_cls: 0.0001713  loss_rpn_loc: 0.003476  total_val_loss: 0.3254  val_loss_cls: 0.07929  val_loss_box_reg: 0.1023  val_loss_mask: 0.1452  val_loss_rpn_cls: 0.0001889  val_loss_rpn_loc: 0.004959  time: 0.1716  data_time: 0.0123  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:29:27 d2.utils.events]: \u001b[0m eta: 0:03:45  iter: 3119  total_loss: 0.2347  loss_cls: 0.04776  loss_box_reg: 0.0844  loss_mask: 0.08414  loss_rpn_cls: 0.000104  loss_rpn_loc: 0.003416  total_val_loss: 0.3046  val_loss_cls: 0.08093  val_loss_box_reg: 0.08407  val_loss_mask: 0.1117  val_loss_rpn_cls: 0.0008776  val_loss_rpn_loc: 0.003399  time: 0.1716  data_time: 0.0097  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:29:32 d2.utils.events]: \u001b[0m eta: 0:03:41  iter: 3139  total_loss: 0.2445  loss_cls: 0.04397  loss_box_reg: 0.07052  loss_mask: 0.1036  loss_rpn_cls: 0.0003161  loss_rpn_loc: 0.004391  total_val_loss: 0.4187  val_loss_cls: 0.1289  val_loss_box_reg: 0.09395  val_loss_mask: 0.1392  val_loss_rpn_cls: 8.89e-05  val_loss_rpn_loc: 0.004877  time: 0.1716  data_time: 0.0177  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:29:38 d2.utils.events]: \u001b[0m eta: 0:03:38  iter: 3159  total_loss: 0.2099  loss_cls: 0.06094  loss_box_reg: 0.07763  loss_mask: 0.08204  loss_rpn_cls: 0.0001133  loss_rpn_loc: 0.003014  total_val_loss: 0.3021  val_loss_cls: 0.0622  val_loss_box_reg: 0.1111  val_loss_mask: 0.1379  val_loss_rpn_cls: 0.0001295  val_loss_rpn_loc: 0.003346  time: 0.1716  data_time: 0.0130  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:29:43 d2.utils.events]: \u001b[0m eta: 0:03:35  iter: 3179  total_loss: 0.2581  loss_cls: 0.05953  loss_box_reg: 0.08153  loss_mask: 0.09593  loss_rpn_cls: 0.0001201  loss_rpn_loc: 0.003409  total_val_loss: 0.3309  val_loss_cls: 0.1068  val_loss_box_reg: 0.08544  val_loss_mask: 0.09661  val_loss_rpn_cls: 0.0002572  val_loss_rpn_loc: 0.003292  time: 0.1716  data_time: 0.0133  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:29:48 d2.utils.events]: \u001b[0m eta: 0:03:32  iter: 3199  total_loss: 0.2568  loss_cls: 0.05874  loss_box_reg: 0.08755  loss_mask: 0.1059  loss_rpn_cls: 0.0001562  loss_rpn_loc: 0.003915  total_val_loss: 0.3274  val_loss_cls: 0.08581  val_loss_box_reg: 0.104  val_loss_mask: 0.1247  val_loss_rpn_cls: 0.0002416  val_loss_rpn_loc: 0.004103  time: 0.1716  data_time: 0.0116  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:29:54 d2.utils.events]: \u001b[0m eta: 0:03:28  iter: 3219  total_loss: 0.2057  loss_cls: 0.04751  loss_box_reg: 0.06647  loss_mask: 0.0769  loss_rpn_cls: 0.0003596  loss_rpn_loc: 0.003443  total_val_loss: 0.2952  val_loss_cls: 0.07626  val_loss_box_reg: 0.09407  val_loss_mask: 0.1312  val_loss_rpn_cls: 0.0002855  val_loss_rpn_loc: 0.003244  time: 0.1716  data_time: 0.0165  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:29:59 d2.utils.events]: \u001b[0m eta: 0:03:25  iter: 3239  total_loss: 0.2307  loss_cls: 0.05923  loss_box_reg: 0.06904  loss_mask: 0.08719  loss_rpn_cls: 0.0003426  loss_rpn_loc: 0.004068  total_val_loss: 0.3889  val_loss_cls: 0.1304  val_loss_box_reg: 0.1048  val_loss_mask: 0.1291  val_loss_rpn_cls: 0.0002739  val_loss_rpn_loc: 0.004101  time: 0.1717  data_time: 0.0208  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:30:04 d2.utils.events]: \u001b[0m eta: 0:03:22  iter: 3259  total_loss: 0.2273  loss_cls: 0.05124  loss_box_reg: 0.08337  loss_mask: 0.08047  loss_rpn_cls: 0.0001896  loss_rpn_loc: 0.003484  total_val_loss: 0.2611  val_loss_cls: 0.06716  val_loss_box_reg: 0.07645  val_loss_mask: 0.1172  val_loss_rpn_cls: 0.0007241  val_loss_rpn_loc: 0.004383  time: 0.1716  data_time: 0.0069  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:30:09 d2.utils.events]: \u001b[0m eta: 0:03:19  iter: 3279  total_loss: 0.2395  loss_cls: 0.05285  loss_box_reg: 0.07704  loss_mask: 0.1035  loss_rpn_cls: 0.0001763  loss_rpn_loc: 0.003625  total_val_loss: 0.2771  val_loss_cls: 0.09213  val_loss_box_reg: 0.0954  val_loss_mask: 0.1002  val_loss_rpn_cls: 0.0001039  val_loss_rpn_loc: 0.003289  time: 0.1716  data_time: 0.0106  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:30:15 d2.utils.events]: \u001b[0m eta: 0:03:16  iter: 3299  total_loss: 0.2436  loss_cls: 0.05479  loss_box_reg: 0.08699  loss_mask: 0.09037  loss_rpn_cls: 0.0002526  loss_rpn_loc: 0.004646  total_val_loss: 0.4517  val_loss_cls: 0.1392  val_loss_box_reg: 0.14  val_loss_mask: 0.1207  val_loss_rpn_cls: 0.0004428  val_loss_rpn_loc: 0.00402  time: 0.1716  data_time: 0.0196  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:30:20 d2.utils.events]: \u001b[0m eta: 0:03:13  iter: 3319  total_loss: 0.2842  loss_cls: 0.0751  loss_box_reg: 0.09673  loss_mask: 0.09861  loss_rpn_cls: 0.0002242  loss_rpn_loc: 0.003564  total_val_loss: 0.3185  val_loss_cls: 0.0708  val_loss_box_reg: 0.08253  val_loss_mask: 0.1408  val_loss_rpn_cls: 0.0001809  val_loss_rpn_loc: 0.00396  time: 0.1716  data_time: 0.0081  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:30:25 d2.utils.events]: \u001b[0m eta: 0:03:09  iter: 3339  total_loss: 0.1806  loss_cls: 0.04366  loss_box_reg: 0.06062  loss_mask: 0.0728  loss_rpn_cls: 5.884e-05  loss_rpn_loc: 0.003106  total_val_loss: 0.2895  val_loss_cls: 0.06908  val_loss_box_reg: 0.07956  val_loss_mask: 0.1034  val_loss_rpn_cls: 0.0001086  val_loss_rpn_loc: 0.003823  time: 0.1715  data_time: 0.0054  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:30:30 d2.utils.events]: \u001b[0m eta: 0:03:06  iter: 3359  total_loss: 0.2206  loss_cls: 0.05955  loss_box_reg: 0.068  loss_mask: 0.08594  loss_rpn_cls: 8.451e-05  loss_rpn_loc: 0.002974  total_val_loss: 0.4528  val_loss_cls: 0.1412  val_loss_box_reg: 0.1169  val_loss_mask: 0.1828  val_loss_rpn_cls: 0.000716  val_loss_rpn_loc: 0.003688  time: 0.1715  data_time: 0.0130  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:30:36 d2.utils.events]: \u001b[0m eta: 0:03:03  iter: 3379  total_loss: 0.2391  loss_cls: 0.06694  loss_box_reg: 0.07919  loss_mask: 0.08874  loss_rpn_cls: 8.677e-05  loss_rpn_loc: 0.002963  total_val_loss: 0.3142  val_loss_cls: 0.08436  val_loss_box_reg: 0.08372  val_loss_mask: 0.1046  val_loss_rpn_cls: 0.0002042  val_loss_rpn_loc: 0.004128  time: 0.1715  data_time: 0.0110  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:30:41 d2.utils.events]: \u001b[0m eta: 0:03:00  iter: 3399  total_loss: 0.2111  loss_cls: 0.04751  loss_box_reg: 0.06224  loss_mask: 0.08791  loss_rpn_cls: 1.855e-05  loss_rpn_loc: 0.00301  total_val_loss: 0.3502  val_loss_cls: 0.0935  val_loss_box_reg: 0.09011  val_loss_mask: 0.1234  val_loss_rpn_cls: 0.001555  val_loss_rpn_loc: 0.003607  time: 0.1715  data_time: 0.0191  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:30:46 d2.utils.events]: \u001b[0m eta: 0:02:56  iter: 3419  total_loss: 0.2012  loss_cls: 0.0404  loss_box_reg: 0.07513  loss_mask: 0.07697  loss_rpn_cls: 8.957e-05  loss_rpn_loc: 0.004209  total_val_loss: 0.4066  val_loss_cls: 0.1317  val_loss_box_reg: 0.1272  val_loss_mask: 0.1353  val_loss_rpn_cls: 0.0003396  val_loss_rpn_loc: 0.003218  time: 0.1716  data_time: 0.0184  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:30:52 d2.utils.events]: \u001b[0m eta: 0:02:53  iter: 3439  total_loss: 0.2651  loss_cls: 0.05907  loss_box_reg: 0.08344  loss_mask: 0.09548  loss_rpn_cls: 0.0001291  loss_rpn_loc: 0.003403  total_val_loss: 0.3584  val_loss_cls: 0.0952  val_loss_box_reg: 0.07682  val_loss_mask: 0.1186  val_loss_rpn_cls: 0.0001824  val_loss_rpn_loc: 0.002721  time: 0.1716  data_time: 0.0098  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:30:57 d2.utils.events]: \u001b[0m eta: 0:02:50  iter: 3459  total_loss: 0.2244  loss_cls: 0.04609  loss_box_reg: 0.09181  loss_mask: 0.08115  loss_rpn_cls: 0.0003804  loss_rpn_loc: 0.003874  total_val_loss: 0.3393  val_loss_cls: 0.1107  val_loss_box_reg: 0.09819  val_loss_mask: 0.1305  val_loss_rpn_cls: 0.0002264  val_loss_rpn_loc: 0.003789  time: 0.1716  data_time: 0.0222  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:31:03 d2.utils.events]: \u001b[0m eta: 0:02:46  iter: 3479  total_loss: 0.2027  loss_cls: 0.03563  loss_box_reg: 0.06919  loss_mask: 0.08115  loss_rpn_cls: 0.0001835  loss_rpn_loc: 0.003066  total_val_loss: 0.3258  val_loss_cls: 0.105  val_loss_box_reg: 0.08673  val_loss_mask: 0.108  val_loss_rpn_cls: 0.0001988  val_loss_rpn_loc: 0.003498  time: 0.1716  data_time: 0.0116  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:31:08 d2.utils.events]: \u001b[0m eta: 0:02:43  iter: 3499  total_loss: 0.2858  loss_cls: 0.06482  loss_box_reg: 0.1086  loss_mask: 0.107  loss_rpn_cls: 7.326e-05  loss_rpn_loc: 0.003791  total_val_loss: 0.3451  val_loss_cls: 0.1009  val_loss_box_reg: 0.1121  val_loss_mask: 0.1162  val_loss_rpn_cls: 0.0004676  val_loss_rpn_loc: 0.003722  time: 0.1717  data_time: 0.0180  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:31:13 d2.utils.events]: \u001b[0m eta: 0:02:39  iter: 3519  total_loss: 0.2162  loss_cls: 0.03832  loss_box_reg: 0.08112  loss_mask: 0.08237  loss_rpn_cls: 0.0001286  loss_rpn_loc: 0.004132  total_val_loss: 0.2489  val_loss_cls: 0.0671  val_loss_box_reg: 0.08716  val_loss_mask: 0.1052  val_loss_rpn_cls: 0.000166  val_loss_rpn_loc: 0.003535  time: 0.1717  data_time: 0.0145  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:31:19 d2.utils.events]: \u001b[0m eta: 0:02:36  iter: 3539  total_loss: 0.198  loss_cls: 0.05577  loss_box_reg: 0.059  loss_mask: 0.07309  loss_rpn_cls: 8.369e-05  loss_rpn_loc: 0.002904  total_val_loss: 0.4235  val_loss_cls: 0.1382  val_loss_box_reg: 0.1092  val_loss_mask: 0.1452  val_loss_rpn_cls: 0.000442  val_loss_rpn_loc: 0.004293  time: 0.1717  data_time: 0.0172  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:31:24 d2.utils.events]: \u001b[0m eta: 0:02:33  iter: 3559  total_loss: 0.2319  loss_cls: 0.05542  loss_box_reg: 0.07143  loss_mask: 0.09115  loss_rpn_cls: 0.0001274  loss_rpn_loc: 0.003836  total_val_loss: 0.3377  val_loss_cls: 0.09305  val_loss_box_reg: 0.09944  val_loss_mask: 0.153  val_loss_rpn_cls: 0.0005696  val_loss_rpn_loc: 0.003507  time: 0.1717  data_time: 0.0118  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:31:29 d2.utils.events]: \u001b[0m eta: 0:02:29  iter: 3579  total_loss: 0.2275  loss_cls: 0.05601  loss_box_reg: 0.0842  loss_mask: 0.09547  loss_rpn_cls: 0.0002297  loss_rpn_loc: 0.00357  total_val_loss: 0.236  val_loss_cls: 0.04577  val_loss_box_reg: 0.06796  val_loss_mask: 0.08836  val_loss_rpn_cls: 0.0001454  val_loss_rpn_loc: 0.003891  time: 0.1717  data_time: 0.0171  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:31:35 d2.utils.events]: \u001b[0m eta: 0:02:26  iter: 3599  total_loss: 0.1957  loss_cls: 0.05125  loss_box_reg: 0.06526  loss_mask: 0.07464  loss_rpn_cls: 0.0001305  loss_rpn_loc: 0.002556  total_val_loss: 0.3891  val_loss_cls: 0.1011  val_loss_box_reg: 0.131  val_loss_mask: 0.1345  val_loss_rpn_cls: 0.0004712  val_loss_rpn_loc: 0.004481  time: 0.1716  data_time: 0.0127  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:31:40 d2.utils.events]: \u001b[0m eta: 0:02:23  iter: 3619  total_loss: 0.218  loss_cls: 0.0458  loss_box_reg: 0.0765  loss_mask: 0.09329  loss_rpn_cls: 0.0001552  loss_rpn_loc: 0.003565  total_val_loss: 0.2626  val_loss_cls: 0.09336  val_loss_box_reg: 0.07459  val_loss_mask: 0.1104  val_loss_rpn_cls: 0.0001703  val_loss_rpn_loc: 0.00337  time: 0.1716  data_time: 0.0139  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:31:45 d2.utils.events]: \u001b[0m eta: 0:02:19  iter: 3639  total_loss: 0.1917  loss_cls: 0.04266  loss_box_reg: 0.06368  loss_mask: 0.08527  loss_rpn_cls: 6.1e-05  loss_rpn_loc: 0.003228  total_val_loss: 0.354  val_loss_cls: 0.07709  val_loss_box_reg: 0.1249  val_loss_mask: 0.1208  val_loss_rpn_cls: 8.477e-05  val_loss_rpn_loc: 0.003933  time: 0.1716  data_time: 0.0108  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:31:50 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 3659  total_loss: 0.1954  loss_cls: 0.04302  loss_box_reg: 0.05208  loss_mask: 0.08502  loss_rpn_cls: 3.73e-05  loss_rpn_loc: 0.003185  total_val_loss: 0.4114  val_loss_cls: 0.1326  val_loss_box_reg: 0.1101  val_loss_mask: 0.1619  val_loss_rpn_cls: 0.0002387  val_loss_rpn_loc: 0.003378  time: 0.1715  data_time: 0.0095  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:31:56 d2.utils.events]: \u001b[0m eta: 0:02:13  iter: 3679  total_loss: 0.2075  loss_cls: 0.04036  loss_box_reg: 0.0811  loss_mask: 0.08741  loss_rpn_cls: 0.0001255  loss_rpn_loc: 0.003222  total_val_loss: 0.2854  val_loss_cls: 0.07871  val_loss_box_reg: 0.1024  val_loss_mask: 0.1231  val_loss_rpn_cls: 4.263e-05  val_loss_rpn_loc: 0.002996  time: 0.1716  data_time: 0.0124  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:32:01 d2.utils.events]: \u001b[0m eta: 0:02:09  iter: 3699  total_loss: 0.1877  loss_cls: 0.04211  loss_box_reg: 0.06812  loss_mask: 0.08079  loss_rpn_cls: 0.0001297  loss_rpn_loc: 0.003384  total_val_loss: 0.3244  val_loss_cls: 0.087  val_loss_box_reg: 0.07783  val_loss_mask: 0.1311  val_loss_rpn_cls: 0.001769  val_loss_rpn_loc: 0.003414  time: 0.1716  data_time: 0.0077  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:32:06 d2.utils.events]: \u001b[0m eta: 0:02:06  iter: 3719  total_loss: 0.177  loss_cls: 0.04929  loss_box_reg: 0.06699  loss_mask: 0.0777  loss_rpn_cls: 0.0001209  loss_rpn_loc: 0.002184  total_val_loss: 0.2901  val_loss_cls: 0.05282  val_loss_box_reg: 0.1002  val_loss_mask: 0.114  val_loss_rpn_cls: 0.0001832  val_loss_rpn_loc: 0.004134  time: 0.1715  data_time: 0.0141  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:32:12 d2.utils.events]: \u001b[0m eta: 0:02:03  iter: 3739  total_loss: 0.2464  loss_cls: 0.05404  loss_box_reg: 0.08967  loss_mask: 0.08928  loss_rpn_cls: 6.531e-05  loss_rpn_loc: 0.003734  total_val_loss: 0.4538  val_loss_cls: 0.1257  val_loss_box_reg: 0.1346  val_loss_mask: 0.1744  val_loss_rpn_cls: 0.000412  val_loss_rpn_loc: 0.00465  time: 0.1715  data_time: 0.0143  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:32:17 d2.utils.events]: \u001b[0m eta: 0:02:00  iter: 3759  total_loss: 0.2207  loss_cls: 0.0602  loss_box_reg: 0.0847  loss_mask: 0.07853  loss_rpn_cls: 0.0002103  loss_rpn_loc: 0.003757  total_val_loss: 0.2466  val_loss_cls: 0.07456  val_loss_box_reg: 0.08084  val_loss_mask: 0.08923  val_loss_rpn_cls: 0.0001801  val_loss_rpn_loc: 0.003391  time: 0.1716  data_time: 0.0153  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:32:22 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 3779  total_loss: 0.2391  loss_cls: 0.06029  loss_box_reg: 0.08185  loss_mask: 0.0865  loss_rpn_cls: 4.307e-05  loss_rpn_loc: 0.003031  total_val_loss: 0.325  val_loss_cls: 0.0937  val_loss_box_reg: 0.08411  val_loss_mask: 0.1034  val_loss_rpn_cls: 0.0004053  val_loss_rpn_loc: 0.003182  time: 0.1716  data_time: 0.0145  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:32:28 d2.utils.events]: \u001b[0m eta: 0:01:53  iter: 3799  total_loss: 0.2484  loss_cls: 0.0608  loss_box_reg: 0.07138  loss_mask: 0.09966  loss_rpn_cls: 0.0001396  loss_rpn_loc: 0.003451  total_val_loss: 0.3132  val_loss_cls: 0.1162  val_loss_box_reg: 0.08544  val_loss_mask: 0.1413  val_loss_rpn_cls: 0.0005219  val_loss_rpn_loc: 0.00414  time: 0.1716  data_time: 0.0185  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:32:33 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 3819  total_loss: 0.2073  loss_cls: 0.04894  loss_box_reg: 0.0555  loss_mask: 0.08558  loss_rpn_cls: 6.315e-05  loss_rpn_loc: 0.003274  total_val_loss: 0.3633  val_loss_cls: 0.09334  val_loss_box_reg: 0.1022  val_loss_mask: 0.1278  val_loss_rpn_cls: 0.0002954  val_loss_rpn_loc: 0.00397  time: 0.1716  data_time: 0.0169  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:32:39 d2.utils.events]: \u001b[0m eta: 0:01:47  iter: 3839  total_loss: 0.1825  loss_cls: 0.04531  loss_box_reg: 0.06491  loss_mask: 0.07376  loss_rpn_cls: 0.0002375  loss_rpn_loc: 0.003483  total_val_loss: 0.4462  val_loss_cls: 0.07965  val_loss_box_reg: 0.1017  val_loss_mask: 0.1208  val_loss_rpn_cls: 0.0002189  val_loss_rpn_loc: 0.003672  time: 0.1716  data_time: 0.0112  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:32:44 d2.utils.events]: \u001b[0m eta: 0:01:43  iter: 3859  total_loss: 0.1989  loss_cls: 0.03823  loss_box_reg: 0.06669  loss_mask: 0.08375  loss_rpn_cls: 0.0001197  loss_rpn_loc: 0.003363  total_val_loss: 0.3296  val_loss_cls: 0.1172  val_loss_box_reg: 0.1266  val_loss_mask: 0.1413  val_loss_rpn_cls: 0.001246  val_loss_rpn_loc: 0.003796  time: 0.1716  data_time: 0.0079  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:32:49 d2.utils.events]: \u001b[0m eta: 0:01:40  iter: 3879  total_loss: 0.1898  loss_cls: 0.03936  loss_box_reg: 0.05808  loss_mask: 0.07765  loss_rpn_cls: 5.026e-05  loss_rpn_loc: 0.002593  total_val_loss: 0.2985  val_loss_cls: 0.06636  val_loss_box_reg: 0.08245  val_loss_mask: 0.1163  val_loss_rpn_cls: 0.000519  val_loss_rpn_loc: 0.003593  time: 0.1715  data_time: 0.0077  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:32:54 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 3899  total_loss: 0.1946  loss_cls: 0.04414  loss_box_reg: 0.07227  loss_mask: 0.07774  loss_rpn_cls: 9.063e-05  loss_rpn_loc: 0.002964  total_val_loss: 0.2507  val_loss_cls: 0.06527  val_loss_box_reg: 0.08457  val_loss_mask: 0.09505  val_loss_rpn_cls: 0.000598  val_loss_rpn_loc: 0.003909  time: 0.1715  data_time: 0.0194  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:33:00 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 3919  total_loss: 0.2139  loss_cls: 0.04104  loss_box_reg: 0.08117  loss_mask: 0.09957  loss_rpn_cls: 5.197e-05  loss_rpn_loc: 0.003974  total_val_loss: 0.3644  val_loss_cls: 0.08641  val_loss_box_reg: 0.08027  val_loss_mask: 0.1169  val_loss_rpn_cls: 0.0005956  val_loss_rpn_loc: 0.005583  time: 0.1715  data_time: 0.0116  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:33:05 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 3939  total_loss: 0.2265  loss_cls: 0.04182  loss_box_reg: 0.08015  loss_mask: 0.08918  loss_rpn_cls: 5.291e-05  loss_rpn_loc: 0.002975  total_val_loss: 0.3371  val_loss_cls: 0.09859  val_loss_box_reg: 0.1056  val_loss_mask: 0.1569  val_loss_rpn_cls: 0.0001798  val_loss_rpn_loc: 0.003916  time: 0.1716  data_time: 0.0212  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:33:11 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 3959  total_loss: 0.2325  loss_cls: 0.05129  loss_box_reg: 0.06329  loss_mask: 0.08462  loss_rpn_cls: 0.000141  loss_rpn_loc: 0.003473  total_val_loss: 0.3576  val_loss_cls: 0.1345  val_loss_box_reg: 0.1055  val_loss_mask: 0.1073  val_loss_rpn_cls: 0.0004542  val_loss_rpn_loc: 0.004354  time: 0.1716  data_time: 0.0181  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:33:16 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 3979  total_loss: 0.2157  loss_cls: 0.04374  loss_box_reg: 0.07756  loss_mask: 0.08646  loss_rpn_cls: 7.473e-05  loss_rpn_loc: 0.004195  total_val_loss: 0.3217  val_loss_cls: 0.0629  val_loss_box_reg: 0.1116  val_loss_mask: 0.1266  val_loss_rpn_cls: 0.0002456  val_loss_rpn_loc: 0.002981  time: 0.1717  data_time: 0.0225  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:33:21 d2.utils.events]: \u001b[0m eta: 0:01:20  iter: 3999  total_loss: 0.2021  loss_cls: 0.04194  loss_box_reg: 0.07721  loss_mask: 0.0859  loss_rpn_cls: 0.0001109  loss_rpn_loc: 0.003159  total_val_loss: 0.2406  val_loss_cls: 0.05791  val_loss_box_reg: 0.07411  val_loss_mask: 0.09563  val_loss_rpn_cls: 4.639e-05  val_loss_rpn_loc: 0.003443  time: 0.1716  data_time: 0.0088  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:33:27 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 4019  total_loss: 0.2192  loss_cls: 0.05731  loss_box_reg: 0.06393  loss_mask: 0.08496  loss_rpn_cls: 0.0001321  loss_rpn_loc: 0.00309  total_val_loss: 0.3496  val_loss_cls: 0.111  val_loss_box_reg: 0.122  val_loss_mask: 0.1385  val_loss_rpn_cls: 0.0002136  val_loss_rpn_loc: 0.003397  time: 0.1716  data_time: 0.0134  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:33:32 d2.utils.events]: \u001b[0m eta: 0:01:14  iter: 4039  total_loss: 0.2377  loss_cls: 0.04131  loss_box_reg: 0.07746  loss_mask: 0.08853  loss_rpn_cls: 0.000242  loss_rpn_loc: 0.003652  total_val_loss: 0.3079  val_loss_cls: 0.08916  val_loss_box_reg: 0.1043  val_loss_mask: 0.129  val_loss_rpn_cls: 0.001469  val_loss_rpn_loc: 0.00416  time: 0.1717  data_time: 0.0140  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:33:37 d2.utils.events]: \u001b[0m eta: 0:01:11  iter: 4059  total_loss: 0.1791  loss_cls: 0.03249  loss_box_reg: 0.06273  loss_mask: 0.08004  loss_rpn_cls: 0.0001871  loss_rpn_loc: 0.003293  total_val_loss: 0.3626  val_loss_cls: 0.1204  val_loss_box_reg: 0.0841  val_loss_mask: 0.1207  val_loss_rpn_cls: 0.0001848  val_loss_rpn_loc: 0.00296  time: 0.1716  data_time: 0.0147  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:33:43 d2.utils.events]: \u001b[0m eta: 0:01:07  iter: 4079  total_loss: 0.1924  loss_cls: 0.03639  loss_box_reg: 0.06201  loss_mask: 0.09095  loss_rpn_cls: 0.0001844  loss_rpn_loc: 0.003095  total_val_loss: 0.3146  val_loss_cls: 0.06438  val_loss_box_reg: 0.09958  val_loss_mask: 0.1168  val_loss_rpn_cls: 0.0001077  val_loss_rpn_loc: 0.003153  time: 0.1716  data_time: 0.0129  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:33:48 d2.utils.events]: \u001b[0m eta: 0:01:04  iter: 4099  total_loss: 0.1896  loss_cls: 0.04423  loss_box_reg: 0.05308  loss_mask: 0.08225  loss_rpn_cls: 4.245e-05  loss_rpn_loc: 0.002674  total_val_loss: 0.3553  val_loss_cls: 0.07873  val_loss_box_reg: 0.1097  val_loss_mask: 0.136  val_loss_rpn_cls: 0.001108  val_loss_rpn_loc: 0.004089  time: 0.1717  data_time: 0.0183  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:33:53 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 4119  total_loss: 0.1893  loss_cls: 0.03951  loss_box_reg: 0.06491  loss_mask: 0.0751  loss_rpn_cls: 0.000168  loss_rpn_loc: 0.004067  total_val_loss: 0.3201  val_loss_cls: 0.08925  val_loss_box_reg: 0.09189  val_loss_mask: 0.1124  val_loss_rpn_cls: 0.0005209  val_loss_rpn_loc: 0.003427  time: 0.1716  data_time: 0.0114  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:33:59 d2.utils.events]: \u001b[0m eta: 0:00:57  iter: 4139  total_loss: 0.1974  loss_cls: 0.04205  loss_box_reg: 0.06886  loss_mask: 0.08827  loss_rpn_cls: 0.000107  loss_rpn_loc: 0.004081  total_val_loss: 0.2944  val_loss_cls: 0.07929  val_loss_box_reg: 0.08016  val_loss_mask: 0.105  val_loss_rpn_cls: 0.0002084  val_loss_rpn_loc: 0.004035  time: 0.1717  data_time: 0.0158  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:34:04 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 4159  total_loss: 0.2409  loss_cls: 0.04169  loss_box_reg: 0.08142  loss_mask: 0.08604  loss_rpn_cls: 0.0001481  loss_rpn_loc: 0.004456  total_val_loss: 0.4199  val_loss_cls: 0.1409  val_loss_box_reg: 0.09954  val_loss_mask: 0.1046  val_loss_rpn_cls: 5.562e-05  val_loss_rpn_loc: 0.003318  time: 0.1717  data_time: 0.0168  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:34:09 d2.utils.events]: \u001b[0m eta: 0:00:51  iter: 4179  total_loss: 0.1756  loss_cls: 0.04499  loss_box_reg: 0.05654  loss_mask: 0.07127  loss_rpn_cls: 2.31e-05  loss_rpn_loc: 0.002583  total_val_loss: 0.2898  val_loss_cls: 0.08595  val_loss_box_reg: 0.0681  val_loss_mask: 0.1043  val_loss_rpn_cls: 2.061e-05  val_loss_rpn_loc: 0.002813  time: 0.1717  data_time: 0.0088  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:34:14 d2.utils.events]: \u001b[0m eta: 0:00:47  iter: 4199  total_loss: 0.2038  loss_cls: 0.04012  loss_box_reg: 0.07323  loss_mask: 0.08552  loss_rpn_cls: 0.0001345  loss_rpn_loc: 0.00325  total_val_loss: 0.352  val_loss_cls: 0.07133  val_loss_box_reg: 0.09084  val_loss_mask: 0.1365  val_loss_rpn_cls: 5.539e-05  val_loss_rpn_loc: 0.002918  time: 0.1716  data_time: 0.0106  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:34:20 d2.utils.events]: \u001b[0m eta: 0:00:44  iter: 4219  total_loss: 0.2197  loss_cls: 0.04387  loss_box_reg: 0.07135  loss_mask: 0.08484  loss_rpn_cls: 0.0001547  loss_rpn_loc: 0.003218  total_val_loss: 0.5676  val_loss_cls: 0.16  val_loss_box_reg: 0.1045  val_loss_mask: 0.1101  val_loss_rpn_cls: 0.0002808  val_loss_rpn_loc: 0.00347  time: 0.1716  data_time: 0.0127  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:34:25 d2.utils.events]: \u001b[0m eta: 0:00:41  iter: 4239  total_loss: 0.1956  loss_cls: 0.04518  loss_box_reg: 0.06815  loss_mask: 0.07226  loss_rpn_cls: 1.819e-05  loss_rpn_loc: 0.002783  total_val_loss: 0.3053  val_loss_cls: 0.07473  val_loss_box_reg: 0.08332  val_loss_mask: 0.1194  val_loss_rpn_cls: 0.0003033  val_loss_rpn_loc: 0.003562  time: 0.1716  data_time: 0.0093  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:34:30 d2.utils.events]: \u001b[0m eta: 0:00:37  iter: 4259  total_loss: 0.2052  loss_cls: 0.04451  loss_box_reg: 0.07643  loss_mask: 0.0819  loss_rpn_cls: 0.0001711  loss_rpn_loc: 0.004067  total_val_loss: 0.3424  val_loss_cls: 0.1022  val_loss_box_reg: 0.09188  val_loss_mask: 0.1058  val_loss_rpn_cls: 0.0001172  val_loss_rpn_loc: 0.00302  time: 0.1716  data_time: 0.0072  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:34:36 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 4279  total_loss: 0.2027  loss_cls: 0.04039  loss_box_reg: 0.07291  loss_mask: 0.09059  loss_rpn_cls: 0.0001019  loss_rpn_loc: 0.003139  total_val_loss: 0.3763  val_loss_cls: 0.07979  val_loss_box_reg: 0.1286  val_loss_mask: 0.154  val_loss_rpn_cls: 0.000719  val_loss_rpn_loc: 0.003508  time: 0.1716  data_time: 0.0119  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:34:41 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 4299  total_loss: 0.2123  loss_cls: 0.0435  loss_box_reg: 0.06992  loss_mask: 0.08612  loss_rpn_cls: 0.0003677  loss_rpn_loc: 0.002873  total_val_loss: 0.3816  val_loss_cls: 0.1058  val_loss_box_reg: 0.1102  val_loss_mask: 0.1124  val_loss_rpn_cls: 0.0004905  val_loss_rpn_loc: 0.00399  time: 0.1715  data_time: 0.0091  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:34:46 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 4319  total_loss: 0.1923  loss_cls: 0.04384  loss_box_reg: 0.07462  loss_mask: 0.06742  loss_rpn_cls: 6.29e-05  loss_rpn_loc: 0.003521  total_val_loss: 0.3415  val_loss_cls: 0.1113  val_loss_box_reg: 0.09029  val_loss_mask: 0.1354  val_loss_rpn_cls: 0.0001794  val_loss_rpn_loc: 0.004012  time: 0.1715  data_time: 0.0088  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:34:51 d2.utils.events]: \u001b[0m eta: 0:00:24  iter: 4339  total_loss: 0.2014  loss_cls: 0.03564  loss_box_reg: 0.06984  loss_mask: 0.0873  loss_rpn_cls: 6.711e-05  loss_rpn_loc: 0.002981  total_val_loss: 0.3643  val_loss_cls: 0.08307  val_loss_box_reg: 0.09006  val_loss_mask: 0.1604  val_loss_rpn_cls: 0.0005446  val_loss_rpn_loc: 0.003552  time: 0.1715  data_time: 0.0101  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:34:56 d2.utils.events]: \u001b[0m eta: 0:00:21  iter: 4359  total_loss: 0.1809  loss_cls: 0.03991  loss_box_reg: 0.06897  loss_mask: 0.07133  loss_rpn_cls: 5.108e-05  loss_rpn_loc: 0.002596  total_val_loss: 0.2938  val_loss_cls: 0.1199  val_loss_box_reg: 0.08284  val_loss_mask: 0.1155  val_loss_rpn_cls: 8.982e-05  val_loss_rpn_loc: 0.003763  time: 0.1714  data_time: 0.0070  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:35:02 d2.utils.events]: \u001b[0m eta: 0:00:18  iter: 4379  total_loss: 0.1796  loss_cls: 0.03408  loss_box_reg: 0.06318  loss_mask: 0.07769  loss_rpn_cls: 0.0002092  loss_rpn_loc: 0.004061  total_val_loss: 0.4622  val_loss_cls: 0.1342  val_loss_box_reg: 0.1189  val_loss_mask: 0.1477  val_loss_rpn_cls: 0.0003732  val_loss_rpn_loc: 0.004776  time: 0.1714  data_time: 0.0101  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:35:07 d2.utils.events]: \u001b[0m eta: 0:00:14  iter: 4399  total_loss: 0.1859  loss_cls: 0.03901  loss_box_reg: 0.06142  loss_mask: 0.08013  loss_rpn_cls: 0.0001047  loss_rpn_loc: 0.003513  total_val_loss: 0.4085  val_loss_cls: 0.09779  val_loss_box_reg: 0.1057  val_loss_mask: 0.1215  val_loss_rpn_cls: 0.0005671  val_loss_rpn_loc: 0.004284  time: 0.1714  data_time: 0.0125  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:35:12 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 4419  total_loss: 0.2461  loss_cls: 0.04184  loss_box_reg: 0.07786  loss_mask: 0.1036  loss_rpn_cls: 0.000129  loss_rpn_loc: 0.002872  total_val_loss: 0.381  val_loss_cls: 0.0947  val_loss_box_reg: 0.09582  val_loss_mask: 0.0992  val_loss_rpn_cls: 0.0002054  val_loss_rpn_loc: 0.003554  time: 0.1714  data_time: 0.0111  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:35:18 d2.utils.events]: \u001b[0m eta: 0:00:08  iter: 4439  total_loss: 0.2095  loss_cls: 0.0329  loss_box_reg: 0.06915  loss_mask: 0.1008  loss_rpn_cls: 0.0001351  loss_rpn_loc: 0.003389  total_val_loss: 0.3103  val_loss_cls: 0.112  val_loss_box_reg: 0.08887  val_loss_mask: 0.1133  val_loss_rpn_cls: 0.0002079  val_loss_rpn_loc: 0.004631  time: 0.1714  data_time: 0.0104  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:35:23 d2.utils.events]: \u001b[0m eta: 0:00:04  iter: 4459  total_loss: 0.1823  loss_cls: 0.04301  loss_box_reg: 0.0679  loss_mask: 0.07188  loss_rpn_cls: 0.0001631  loss_rpn_loc: 0.002852  total_val_loss: 0.2582  val_loss_cls: 0.0563  val_loss_box_reg: 0.09294  val_loss_mask: 0.09834  val_loss_rpn_cls: 8.025e-05  val_loss_rpn_loc: 0.002934  time: 0.1714  data_time: 0.0081  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:35:28 d2.utils.events]: \u001b[0m eta: 0:00:01  iter: 4479  total_loss: 0.2025  loss_cls: 0.04648  loss_box_reg: 0.06681  loss_mask: 0.07479  loss_rpn_cls: 0.0001289  loss_rpn_loc: 0.003165  total_val_loss: 0.4067  val_loss_cls: 0.1184  val_loss_box_reg: 0.08427  val_loss_mask: 0.1419  val_loss_rpn_cls: 0.0001338  val_loss_rpn_loc: 0.003255  time: 0.1714  data_time: 0.0147  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:35:31 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 4488  total_loss: 0.2001  loss_cls: 0.04445  loss_box_reg: 0.07305  loss_mask: 0.07668  loss_rpn_cls: 7.99e-05  loss_rpn_loc: 0.00316  total_val_loss: 0.4613  val_loss_cls: 0.09938  val_loss_box_reg: 0.09118  val_loss_mask: 0.1588  val_loss_rpn_cls: 0.0001059  val_loss_rpn_loc: 0.003578  time: 0.1714  data_time: 0.0120  lr: 0.00025  max_mem: 2226M\n",
            "\u001b[32m[06/14 03:35:33 d2.engine.hooks]: \u001b[0mOverall training speed: 4487 iterations in 0:12:49 (0.1714 s / it)\n",
            "\u001b[32m[06/14 03:35:33 d2.engine.hooks]: \u001b[0mTotal training time: 0:19:59 (0:07:10 on hooks)\n"
          ]
        }
      ],
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = DefaultTrainer(cfg) \n",
        "val_loss = ValidationLoss(cfg)  \n",
        "trainer.register_hooks([val_loss])\n",
        "# swap the order of PeriodicWriter and ValidationLoss\n",
        "trainer._hooks = trainer._hooks[:-2] + trainer._hooks[-2:][::-1]\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0udjIrFxe-M"
      },
      "outputs": [],
      "source": [
        "# Look at training and val curves in tensorboard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tji2YeIKt_dW"
      },
      "source": [
        "### Download the weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwccR7dft7fQ"
      },
      "outputs": [],
      "source": [
        "!zip -r /content/weight.zip /content/ouput \n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"/content/weight.zip\") "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e4vdDIOXyxF"
      },
      "source": [
        "## Inference on validation set using the trained model\n",
        "Now, let's run inference with the trained model on the building validation dataset. First, let's create a predictor using the model we just trained:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ya5nEuMELeq8"
      },
      "outputs": [],
      "source": [
        "# Inference should use the config with parameters that are used in training\n",
        "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.80   # set a custom testing threshold\n",
        "predictor = DefaultPredictor(cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWq1XHfDWiXO"
      },
      "source": [
        "Then, we randomly select several samples to visualize the prediction results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "U5LhISJqWXgM"
      },
      "outputs": [],
      "source": [
        "from detectron2.utils.visualizer import ColorMode\n",
        "dataset_dicts = get_building_dicts(DATASET_ADDRESS+\"/val\")\n",
        "# From here to change the numer of imgs to show\n",
        "# num_to_show = 1\n",
        "# for d in random.sample(dataset_dicts,num_to_show):  \n",
        "for d in dataset_dicts[:2]:\n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=building_metadata, \n",
        "                   scale=0.5, \n",
        "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
        "    )\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "\n",
        "    img_name = 'predict_'+d[\"file_name\"].split('/')[-1]\n",
        "    savepath = '/content/val_predict/' + img_name\n",
        "    cv2.imwrite(savepath, out.get_image()[:, :, ::-1])\n",
        "    cv2_imshow(out.get_image()[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D70wcfcP9-Ty"
      },
      "source": [
        "We can also evaluate its performance using AP metric implemented in COCO API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-KKcG-t93hX",
        "outputId": "c7c86087-303f-483c-a88c-08e3a7fc4370"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m[06/14 03:35:39 d2.evaluation.coco_evaluation]: \u001b[0m'building_val' is not registered by `register_coco_instances`. Therefore trying to convert it to COCO format ...\n",
            "\u001b[32m[06/14 03:35:39 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'building_val' to COCO format ...)\n",
            "\u001b[32m[06/14 03:35:41 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
            "\u001b[32m[06/14 03:35:41 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 96, #annotations: 123\n",
            "\u001b[32m[06/14 03:35:42 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './output/building_val_coco_format.json' ...\n",
            "\u001b[32m[06/14 03:35:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[06/14 03:35:44 d2.data.common]: \u001b[0mSerializing 96 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[06/14 03:35:44 d2.data.common]: \u001b[0mSerialized dataset takes 0.08 MiB\n",
            "\u001b[32m[06/14 03:35:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 96 images\n",
            "\u001b[32m[06/14 03:35:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/96. 0.0443 s / img. ETA=0:00:14\n",
            "\u001b[32m[06/14 03:35:52 d2.evaluation.evaluator]: \u001b[0mInference done 81/96. 0.0370 s / img. ETA=0:00:01\n",
            "\u001b[32m[06/14 03:35:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.652272 (0.073102 s / img per device, on 1 devices)\n",
            "\u001b[32m[06/14 03:35:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:03 (0.036365 s / img per device, on 1 devices)\n",
            "\u001b[32m[06/14 03:35:52 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[06/14 03:35:52 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
            "\u001b[32m[06/14 03:35:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[06/14 03:35:52 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[06/14 03:35:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.02 seconds.\n",
            "\u001b[32m[06/14 03:35:52 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[06/14 03:35:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.542\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.770\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.539\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.542\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.589\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.706\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.706\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.706\n",
            "\u001b[32m[06/14 03:35:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 54.224 | 77.049 | 53.945 |  nan  |  nan  | 54.232 |\n",
            "\u001b[32m[06/14 03:35:52 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
            "\u001b[32m[06/14 03:35:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| masonry    | 52.313 | m6         | 43.810 | rcw        | 66.549 |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[06/14 03:35:52 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
            "\u001b[32m[06/14 03:35:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.04 seconds.\n",
            "\u001b[32m[06/14 03:35:52 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[06/14 03:35:52 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.557\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.770\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.569\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.558\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.598\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.718\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.718\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.718\n",
            "\u001b[32m[06/14 03:35:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 55.743 | 77.049 | 56.852 |  nan  |  nan  | 55.752 |\n",
            "\u001b[32m[06/14 03:35:52 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
            "\u001b[32m[06/14 03:35:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| masonry    | 51.717 | m6         | 45.991 | rcw        | 69.522 |\n",
            "OrderedDict([('bbox', {'AP': 54.22369639279117, 'AP50': 77.04869060198153, 'AP75': 53.94477242211691, 'APs': nan, 'APm': nan, 'APl': 54.232060951051494, 'AP-masonry': 52.3129735206291, 'AP-m6': 43.80955298855868, 'AP-rcw': 66.54856266918571}), ('segm', {'AP': 55.74331625572167, 'AP50': 77.04869060198153, 'AP75': 56.85194660813714, 'APs': nan, 'APm': nan, 'APl': 55.752042692275104, 'AP-masonry': 51.71691250057867, 'AP-m6': 45.99058152213461, 'AP-rcw': 69.52245474445172})])\n"
          ]
        }
      ],
      "source": [
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "evaluator = COCOEvaluator(\"building_val\", (\"bbox\", \"segm\"), False, output_dir=\"./output/\")\n",
        "val_loader = build_detection_test_loader(cfg, \"building_val\")\n",
        "print(inference_on_dataset(trainer.model, val_loader, evaluator))\n",
        "# another equivalent way to evaluate the model is to use `trainer.test`"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "model2_train.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    },
    "kernelspec": {
      "display_name": "Python 3.8.2 64-bit",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}